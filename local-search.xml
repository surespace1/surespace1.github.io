<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>循环神经网络</title>
    <link href="/2024/07/29/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88RNN%EF%BC%89/"/>
    <url>/2024/07/29/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88RNN%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="基础结构"><a href="#基础结构" class="headerlink" title="基础结构"></a>基础结构</h1><h2 id="计算过程"><a href="#计算过程" class="headerlink" title="计算过程"></a>计算过程</h2><p>​<img src="/assets/rnn/image-20240503154316-u9iie3c.png" alt="image" title="RNN时间展开图">​</p><p>$公式1：s_t&#x3D;f(U<em>x_t+W</em>s_{t-1})$</p><p>隐藏层的计算公式，是循环层。U是输入x的权重矩阵，w是权重矩阵，f是激活函数</p><p>$公式2：o_t&#x3D;g(V*s_t)$</p><p>输出层的计算公式。v是输出层的权重矩阵，g是激活函数</p><h1 id="BRNN（双向循环神经网络）"><a href="#BRNN（双向循环神经网络）" class="headerlink" title="BRNN（双向循环神经网络）"></a>BRNN（双向循环神经网络）</h1><p>​<img src="/assets/rnn/image-20240503160331-1eklkdn.png" alt="image">​</p><p>$\mathrm{y}_2&#x3D;g(VA_2+V’A_2’)$</p><p>$A_2&#x3D;f(WA_1+U\mathrm{x}_2)$</p><p>$A_2’&#x3D;f(W’A_3’+U’\mathrm{x}_2)$</p><p>正向计算时，隐藏层的值𝑆𝑡与𝑆𝑡−1有关；反向计算时，隐藏层的值𝑆𝑡′与𝑆𝑡+1′有关；最终的输出取决于正向和反向计算的加和</p><p>正向计算和反向计算都不共享权重</p><h1 id="LSTM（长短时记忆网络）"><a href="#LSTM（长短时记忆网络）" class="headerlink" title="LSTM（长短时记忆网络）"></a>LSTM（长短时记忆网络）</h1><p>遗忘门，记忆门，输出门</p><h2 id="计算过程-1"><a href="#计算过程-1" class="headerlink" title="计算过程"></a>计算过程</h2><p>​<img src="/assets/rnn/image-20240503160836-39sjnyr.png" alt="image">​</p><p>记忆单元状态的计算公式</p><p>$公式1：c_{t}&#x3D;f_{t} \odot c_{t-1}+i_{t} \odot g_t $</p><p>遗忘门：</p><p>$f_t$称为遗忘门，表明$c_{t-1}$的哪些特征被记录从而计算$c_t$， 通常使用$sigmoid$函数作为激活函数</p><p>$公式2：f_t&#x3D;\sigma (x_tW_x^{(f)}+h_{h-1}W_h^{(f)}+b^{(f)})$</p><p>输入门：</p><p>$\tilde{C}_t$是单元状态更新值，激活函数通常是$tanh$，$i_t $为输入门</p><p>$公式3:：i_t&#x3D;\sigma (x_tW_x^{(i)}+h_{t-1}W_h^{i}+b^{(i)})$</p><p>$公式4：g_t&#x3D;tanh(x_tW_x^{(g)}+h_{t-1}W_h^{(g)}+b^{(g)})$</p><p>输出门：</p><p>$公式5：o_t&#x3D;\sigma (x_tW_x^{(o)}+h_{t-1}W_h^{(o)}+b^{(o)})$</p><p>$公式6：h_t&#x3D;o_t\odot tanh(c_t)$</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><br><span class="hljs-comment"># Define LSTM Neural Networks</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LstmRNN</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Parameters：</span><br><span class="hljs-string">        - input_size: feature size</span><br><span class="hljs-string">        - hidden_size: number of hidden units</span><br><span class="hljs-string">        - output_size: number of output</span><br><span class="hljs-string">        - num_layers: layers of LSTM to stack</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size=<span class="hljs-number">1</span>, output_size=<span class="hljs-number">1</span>, num_layers=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)  <span class="hljs-comment"># utilize the LSTM model in torch.nn</span><br>        self.forwardCalculation = nn.Linear(hidden_size, output_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, _x</span>):<br>        x, _ = self.lstm(_x)  <span class="hljs-comment"># _x is input, size (seq_len, batch, input_size)</span><br>        s, b, h = x.shape  <span class="hljs-comment"># x is output, size (seq_len, batch, hidden_size)</span><br>        x = x.view(s * b, h)<br>        x = self.forwardCalculation(x)<br>        x = x.view(s, b, -<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># create database</span><br>    data_len = <span class="hljs-number">200</span><br>    t = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">12</span> * np.pi, data_len)<br>    sin_t = np.sin(t)<br>    cos_t = np.cos(t)<br><br>    dataset = np.zeros((data_len, <span class="hljs-number">2</span>))<br>    dataset[:, <span class="hljs-number">0</span>] = sin_t<br>    dataset[:, <span class="hljs-number">1</span>] = cos_t<br>    dataset = dataset.astype(<span class="hljs-string">&#x27;float32&#x27;</span>)<br><br>    <span class="hljs-comment"># plot part of the original dataset</span><br>    plt.figure()<br>    plt.plot(t[<span class="hljs-number">0</span>:<span class="hljs-number">60</span>], dataset[<span class="hljs-number">0</span>:<span class="hljs-number">60</span>, <span class="hljs-number">0</span>], label=<span class="hljs-string">&#x27;sin(t)&#x27;</span>)<br>    plt.plot(t[<span class="hljs-number">0</span>:<span class="hljs-number">60</span>], dataset[<span class="hljs-number">0</span>:<span class="hljs-number">60</span>, <span class="hljs-number">1</span>], label=<span class="hljs-string">&#x27;cos(t)&#x27;</span>)<br>    plt.plot([<span class="hljs-number">2.5</span>, <span class="hljs-number">2.5</span>], [-<span class="hljs-number">1.3</span>, <span class="hljs-number">0.55</span>], <span class="hljs-string">&#x27;r--&#x27;</span>, label=<span class="hljs-string">&#x27;t = 2.5&#x27;</span>)  <span class="hljs-comment"># t = 2.5</span><br>    plt.plot([<span class="hljs-number">6.8</span>, <span class="hljs-number">6.8</span>], [-<span class="hljs-number">1.3</span>, <span class="hljs-number">0.85</span>], <span class="hljs-string">&#x27;m--&#x27;</span>, label=<span class="hljs-string">&#x27;t = 6.8&#x27;</span>)  <span class="hljs-comment"># t = 6.8</span><br>    plt.xlabel(<span class="hljs-string">&#x27;t&#x27;</span>)<br>    plt.ylim(-<span class="hljs-number">1.2</span>, <span class="hljs-number">1.2</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;sin(t) and cos(t)&#x27;</span>)<br>    plt.legend(loc=<span class="hljs-string">&#x27;upper right&#x27;</span>)<br><br>    <span class="hljs-comment"># choose dataset for training and testing</span><br>    train_data_ratio = <span class="hljs-number">0.5</span>  <span class="hljs-comment"># Choose 80% of the data for testing</span><br>    train_data_len = <span class="hljs-built_in">int</span>(data_len * train_data_ratio)<br>    train_x = dataset[:train_data_len, <span class="hljs-number">0</span>]<br>    train_y = dataset[:train_data_len, <span class="hljs-number">1</span>]<br>    INPUT_FEATURES_NUM = <span class="hljs-number">1</span><br>    OUTPUT_FEATURES_NUM = <span class="hljs-number">1</span><br>    t_for_training = t[:train_data_len]<br><br>    <span class="hljs-comment"># test_x = train_x</span><br>    <span class="hljs-comment"># test_y = train_y</span><br>    test_x = dataset[train_data_len:, <span class="hljs-number">0</span>]<br>    test_y = dataset[train_data_len:, <span class="hljs-number">1</span>]<br>    t_for_testing = t[train_data_len:]<br><br>    <span class="hljs-comment"># ----------------- train -------------------</span><br>    train_x_tensor = train_x.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">5</span>, INPUT_FEATURES_NUM)  <span class="hljs-comment"># set batch size to 5</span><br>    train_y_tensor = train_y.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">5</span>, OUTPUT_FEATURES_NUM)  <span class="hljs-comment"># set batch size to 5</span><br><br>    <span class="hljs-comment"># transfer data to pytorch tensor</span><br>    train_x_tensor = torch.from_numpy(train_x_tensor)<br>    train_y_tensor = torch.from_numpy(train_y_tensor)<br>    <span class="hljs-comment"># test_x_tensor = torch.from_numpy(test_x)</span><br><br>    lstm_model = LstmRNN(INPUT_FEATURES_NUM, <span class="hljs-number">16</span>, output_size=OUTPUT_FEATURES_NUM, num_layers=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 16 hidden units</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;LSTM model:&#x27;</span>, lstm_model)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;model.parameters:&#x27;</span>, lstm_model.parameters)<br><br>    loss_function = nn.MSELoss()<br>    optimizer = torch.optim.Adam(lstm_model.parameters(), lr=<span class="hljs-number">1e-2</span>)<br><br>    max_epochs = <span class="hljs-number">10000</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_epochs):<br>        output = lstm_model(train_x_tensor)<br>        loss = loss_function(output, train_y_tensor)<br><br>        loss.backward()<br>        optimizer.step()<br>        optimizer.zero_grad()<br><br>        <span class="hljs-keyword">if</span> loss.item() &lt; <span class="hljs-number">1e-4</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch [&#123;&#125;/&#123;&#125;], Loss: &#123;:.5f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch + <span class="hljs-number">1</span>, max_epochs, loss.item()))<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;The loss value is reached&quot;</span>)<br>            <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">elif</span> (epoch + <span class="hljs-number">1</span>) % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch: [&#123;&#125;/&#123;&#125;], Loss:&#123;:.5f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch + <span class="hljs-number">1</span>, max_epochs, loss.item()))<br><br>    <span class="hljs-comment"># prediction on training dataset</span><br>    predictive_y_for_training = lstm_model(train_x_tensor)<br>    predictive_y_for_training = predictive_y_for_training.view(-<span class="hljs-number">1</span>, OUTPUT_FEATURES_NUM).data.numpy()<br><br>    <span class="hljs-comment"># torch.save(lstm_model.state_dict(), &#x27;model_params.pkl&#x27;) # save model parameters to files</span><br><br>    <span class="hljs-comment"># ----------------- test -------------------</span><br>    <span class="hljs-comment"># lstm_model.load_state_dict(torch.load(&#x27;model_params.pkl&#x27;))  # load model parameters from files</span><br>    lstm_model = lstm_model.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># switch to testing model</span><br><br>    <span class="hljs-comment"># prediction on test dataset</span><br>    test_x_tensor = test_x.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">5</span>,<br>                                   INPUT_FEATURES_NUM)  <span class="hljs-comment"># set batch size to 5, the same value with the training set</span><br>    test_x_tensor = torch.from_numpy(test_x_tensor)<br><br>    predictive_y_for_testing = lstm_model(test_x_tensor)<br>    predictive_y_for_testing = predictive_y_for_testing.view(-<span class="hljs-number">1</span>, OUTPUT_FEATURES_NUM).data.numpy()<br><br>    <span class="hljs-comment"># ----------------- plot -------------------</span><br>    plt.figure()<br>    plt.plot(t_for_training, train_x, <span class="hljs-string">&#x27;g&#x27;</span>, label=<span class="hljs-string">&#x27;sin_trn&#x27;</span>)<br>    plt.plot(t_for_training, train_y, <span class="hljs-string">&#x27;b&#x27;</span>, label=<span class="hljs-string">&#x27;ref_cos_trn&#x27;</span>)<br>    plt.plot(t_for_training, predictive_y_for_training, <span class="hljs-string">&#x27;y--&#x27;</span>, label=<span class="hljs-string">&#x27;pre_cos_trn&#x27;</span>)<br><br>    plt.plot(t_for_testing, test_x, <span class="hljs-string">&#x27;c&#x27;</span>, label=<span class="hljs-string">&#x27;sin_tst&#x27;</span>)<br>    plt.plot(t_for_testing, test_y, <span class="hljs-string">&#x27;k&#x27;</span>, label=<span class="hljs-string">&#x27;ref_cos_tst&#x27;</span>)<br>    plt.plot(t_for_testing, predictive_y_for_testing, <span class="hljs-string">&#x27;m--&#x27;</span>, label=<span class="hljs-string">&#x27;pre_cos_tst&#x27;</span>)<br><br>    plt.plot([t[train_data_len], t[train_data_len]], [-<span class="hljs-number">1.2</span>, <span class="hljs-number">4.0</span>], <span class="hljs-string">&#x27;r--&#x27;</span>, label=<span class="hljs-string">&#x27;separation line&#x27;</span>)  <span class="hljs-comment"># separation line</span><br><br>    plt.xlabel(<span class="hljs-string">&#x27;t&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;sin(t) and cos(t)&#x27;</span>)<br>    plt.xlim(t[<span class="hljs-number">0</span>], t[-<span class="hljs-number">1</span>])<br>    plt.ylim(-<span class="hljs-number">1.2</span>, <span class="hljs-number">4</span>)<br>    plt.legend(loc=<span class="hljs-string">&#x27;upper right&#x27;</span>)<br>    plt.text(<span class="hljs-number">14</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&quot;train&quot;</span>, size=<span class="hljs-number">15</span>, alpha=<span class="hljs-number">1.0</span>)<br>    plt.text(<span class="hljs-number">20</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&quot;test&quot;</span>, size=<span class="hljs-number">15</span>, alpha=<span class="hljs-number">1.0</span>)<br><br>    plt.show()<br></code></pre></td></tr></table></figure><h1 id="GRU（门控循环单元）"><a href="#GRU（门控循环单元）" class="headerlink" title="GRU（门控循环单元）"></a>GRU（门控循环单元）</h1><h2 id="计算过程-2"><a href="#计算过程-2" class="headerlink" title="计算过程"></a>计算过程</h2><p>​<img src="/assets/rnn/image-20240503161127-1i7ulhi.png" alt="image">​</p><p>$公式2.1：z&#x3D;\sigma(x_t W_x^{(z)}+h_{t-1} W_h^{(z)}+b^{(z)})$</p><p>$公式2.2：r&#x3D;\sigma(x_t W_x^{(r)}+h_{t-1} W_h^{(r)}+b^{(r)})$</p><p>‍</p><p>$公式2.3：\tilde{h}&#x3D;\tanh (x_t W_x+(r \odot h_{t-1}) W_h+b)$</p><p>$公式2.4：h_t&#x3D;(1-z) \odot h_{t-1}+z \odot \tilde{h}$</p><p>没有记忆单元，只有一个隐藏状态h在时间上的传播</p><p>𝑟(reset门)决定在多大程度上“忽略”过去的隐藏状态。根据公式2.3，如果𝑟是 0，则新的隐藏状态ℎ~仅取决于输入𝑥𝑡。也就是说，此时过去的隐藏状态将完全被忽略。</p><p>𝑧(update门)是更新隐藏状态的门，它扮演了 LSTM 的 forget 门和input 门两个角色。公式2.4 的(1−𝑧)⊙ℎ𝑡−1部分充当 forget 门的功能，从过去的隐藏状态中删除应该被遗忘的信息。𝑧⊙ℎ~的部分充当 input 门的功能，对新增的信息进行加权。</p><p>‍</p><p>参考资料：<a href="https://zybuluo.com/hanbingtao/note/541458">零基础入门深度学习(5) - 循环神经网络</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据结构——排序</title>
    <link href="/2024/06/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E2%80%94%E2%80%94%E6%8E%92%E5%BA%8F/"/>
    <url>/2024/06/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E2%80%94%E2%80%94%E6%8E%92%E5%BA%8F/</url>
    
    <content type="html"><![CDATA[<p>排序：将列表转化为有规律的排序</p><p>内置排序函数：sort()</p><h2 id="排序算法的稳定性"><a href="#排序算法的稳定性" class="headerlink" title="排序算法的稳定性"></a>排序算法的稳定性</h2><p>在原有的序列中，稳定排序算法会让原本有相等键值的记录维持相对次序。也就是如果一个排序算法是稳定的，当有两个相等键值的记录R和S，且在原本的列表中R出现在S之前，在排序过的列表中R也将会出现在S之前。</p><p><u>不稳定排序算法可能会在相等的键值中改变记录的相对次序</u></p><p>​<img src="/assets/image-20240216105555-b54ebs7.png" alt="image">​</p><p>​<img src="/assets/%E6%8E%92%E5%BA%8F%E5%88%86%E7%B1%BB%E5%9B%BE-20240222093911-5kxl43t.png" alt="排序分类图">​</p><h2 id="冒泡排序Bubble-Sort"><a href="#冒泡排序Bubble-Sort" class="headerlink" title="冒泡排序Bubble Sort"></a>冒泡排序Bubble Sort</h2><p><u>越小的元素会经由交换慢慢浮到顶端</u></p><p>冒泡排序的运作如下：</p><ul><li>比较相邻的元素。如果第一个比第二个大（升序），就交换它们两个</li><li>对每一对相邻的元素做同样的工作，从开始第一对到结尾的最后一对。做完这步后，最后的元素会是最大的数。</li><li>针对所有元素重复以上的步骤，除了最后一个。</li><li>持续每次对越来越少的元素重复以上的步骤，直到没有任何一对数字需要比较为止</li></ul><p>​<img src="/assets/image-20240127102352-fft9bbq.png" alt="image" title="冒泡排序过程分析">​</p><p>由上可得，对于一个含n个元素的列表，遍历n-1次</p><p>每次的比较次数如下：</p><p>​<img src="/assets/1%E3%80%81%E7%AE%97%E6%B3%95%20Image8-20240128132114-042vc9r.jpg" alt="1、算法 Image[8]">​</p><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">bubble_sort</span>(<span class="hljs-params">alist: <span class="hljs-built_in">list</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;一个冒泡排序&quot;&quot;&quot;</span><br>    n = <span class="hljs-built_in">len</span>(alist)<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, n-<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, n-j-<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> alist[i] &gt; alist[i + <span class="hljs-number">1</span>]:<br>                alist[i], alist[i+<span class="hljs-number">1</span>] = alist[i+<span class="hljs-number">1</span>], alist[i]<br></code></pre></td></tr></table></figure><p><strong>时间复杂度：</strong>​<strong>O(n) ~ O(n</strong><sup><strong>2</strong></sup> <strong>)</strong> </p><p>稳定性：稳定</p><h3 id="双向冒泡排序"><a href="#双向冒泡排序" class="headerlink" title="双向冒泡排序"></a>双向冒泡排序</h3><h2 id="选择排序Selection-Sort"><a href="#选择排序Selection-Sort" class="headerlink" title="选择排序Selection Sort"></a>选择排序Selection Sort</h2><p>首先<u>在未排序序列中找到最小(大)元素，存放到排序序列的起始位置</u>，然后，再从剩余未排序元素中继续寻找最小(大)元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排满为止</p><p>如果某个元素处于正确的最终位置上，则它不会被移动走。</p><p>选择排序每交换一次，它们中直少有一会移动到最终位置上，因此&#x3D;&#x3D;对于n个元素，最多进行n-1次交换&#x3D;&#x3D;</p><p>​<img src="/assets/image-20240128150855-kjy9atw.png" alt="image" title="选择排序过程分析">​</p><h3 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">select_sort</span>(<span class="hljs-params">alist: <span class="hljs-built_in">list</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;选择排序&quot;&quot;&quot;</span><br>    n = <span class="hljs-built_in">len</span>(alist)<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, n-<span class="hljs-number">1</span>):<br>        min_index = j<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(j+<span class="hljs-number">1</span>, n):<br>            <span class="hljs-keyword">if</span> alist[min_index] &gt; alist[i]:<br>                min_index = i<br>        alist[j], alist[min_index] = alist[min_index], alist[j]<br><br></code></pre></td></tr></table></figure><p><strong>时间复杂度：</strong>​&#x3D;&#x3D;<strong>O(n^2)</strong>&#x3D;&#x3D;</p><p>稳定性：不稳定</p><h2 id="插入排序Insertion-Sort"><a href="#插入排序Insertion-Sort" class="headerlink" title="插入排序Insertion Sort"></a>插入排序Insertion Sort</h2><p><u>通过构建有序列表，对未排序数据，在已排序序列中从后往前扫描，找到相应位置并且插入</u>。插入排序在实现上，在从后往前扫描过程中，需要反复把已排序元素逐步向后挪为最新元素提供空间。</p><p>​<img src="/assets/image-20240128151301-p9syok1.png" alt="image" title="插入算法分析">​</p><h3 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">insert_sort</span>(<span class="hljs-params">alist: <span class="hljs-built_in">list</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;插入排序&quot;&quot;&quot;</span><br>    n = <span class="hljs-built_in">len</span>(alist)<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n):<br>        i = j<br>        <span class="hljs-keyword">while</span> i &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">if</span> alist[i] &lt; alist[i-<span class="hljs-number">1</span>]:<br>                alist[i], alist[i-<span class="hljs-number">1</span>] = alist[i-<span class="hljs-number">1</span>], alist[i]<br>                i -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><p><strong>时间复杂度：</strong>​**&#x3D;&#x3D;O(n)~O(n^2)&#x3D;&#x3D;**</p><p>稳定性：稳定</p><h2 id="希尔排序-Shell-Sort"><a href="#希尔排序-Shell-Sort" class="headerlink" title="希尔排序(Shell Sort)"></a>希尔排序(Shell Sort)</h2><p>希尔排序（shell sort）是插入排序的一种。也称&#x3D;&#x3D;缩小增量排序&#x3D;&#x3D;，是直接插入排序算法的一种更高效的改进版本。希尔算法是非稳定排序算法。希尔排序是<u>把记录按下标的一定增量分组，对每组使用直接插入算法排序；随着增量逐渐减小，每组包含的关键词越来越多，当增量减小到1的时候，整个文件恰好被分成一组，算法便终止。</u></p><h4 id="希尔排序过程"><a href="#希尔排序过程" class="headerlink" title="希尔排序过程"></a>希尔排序过程</h4><p>将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次使用更长的列来进行。最后整个表就只有一列了。将数组转换为表是</p><p>​<img src="/assets/image-20240220111527-7qhbvb2.png" alt="image">​</p><p>为了更好的表达这种算法，其本质任然是使用数组进行排列</p><p>​<img src="/assets/image-20240216104454-i877jod.png" alt="image">​</p><p>​<img src="/assets/image-20240216104943-4iv3x2o.png" alt="image">​</p><h3 id="代码实现-3"><a href="#代码实现-3" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">shell_insert</span>(<span class="hljs-params">alist</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;希尔排序&quot;&quot;&quot;</span><br>    n = <span class="hljs-built_in">len</span>(alist)<br>    gap = n // <span class="hljs-number">2</span><br>    <span class="hljs-keyword">while</span> gap &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(gap, n):<br>            <span class="hljs-keyword">while</span> i &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> alist[i] &lt; alist[i - gap]:<br>                    alist[i], alist[i - gap] = alist[i - gap], alist[i]<br>                    i -= gap<br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">break</span><br>        gap //= <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>时间复杂度：</p><p>最优时间复杂度：根据步长序列的不同而不同</p><p>最坏时间复杂度：O(n<sup>2</sup>)</p><p>稳定性：&#x3D;&#x3D;不稳定&#x3D;&#x3D;</p><h2 id="快速排序-Quick-Sort-（重点）"><a href="#快速排序-Quick-Sort-（重点）" class="headerlink" title="快速排序(Quick Sort)（重点）"></a>快速排序(Quick Sort)（重点）</h2><p>又称为&#x3D;&#x3D;划分交换排序&#x3D;&#x3D;，<u>通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另一部分小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列</u></p><p>基于分治的排序</p><p>步骤为：</p><p>从数列中挑出一个元素，称为基准</p><p>重新排序数列，所有元素比基准小的摆放在基准的前面，大的则放在后面</p><p>递归的把小于基准值元素的子数列和大于基准值元素的子序列排序</p><p>（难度较高）</p><p>‍</p><h3 id="代码实现-4"><a href="#代码实现-4" class="headerlink" title="代码实现"></a>代码实现</h3><p>python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">quick_sort</span>(<span class="hljs-params">alist: <span class="hljs-built_in">list</span>, first, last</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;快速排序&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> first &gt;= last:<br>        <span class="hljs-keyword">return</span><br>    mid_value = alist[first]<br>    low = first<br>    high = last<br>    <span class="hljs-keyword">while</span> low &lt; high:<br>        <span class="hljs-comment"># high左移</span><br>        <span class="hljs-keyword">while</span> low &lt; high <span class="hljs-keyword">and</span> alist[high] &gt;= mid_value:<br>            high -= <span class="hljs-number">1</span><br>        alist[low] = alist[high]<br><br>        <span class="hljs-keyword">while</span> low &lt; high <span class="hljs-keyword">and</span> alist[low] &lt; mid_value:<br>            low += <span class="hljs-number">1</span><br>        alist[high] = alist[low]<br>    <span class="hljs-comment"># 从循环退出时，high=low</span><br>    alist[low] = mid_value<br><br>    <span class="hljs-comment"># 对low左边的列表执行排序</span><br>    quick_sort(alist, first, low-<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 对low右边的进行排序</span><br>    quick_sort(alist, low + <span class="hljs-number">1</span>, last)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    x1 = [<span class="hljs-number">43</span>, <span class="hljs-number">23</span>, <span class="hljs-number">33</span>, <span class="hljs-number">13</span>, <span class="hljs-number">56</span>, <span class="hljs-number">65</span>, <span class="hljs-number">35</span>, <span class="hljs-number">36</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9</span>]<br>    quick_sort(x1, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x1)-<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(x1）<br></code></pre></td></tr></table></figure><p>c++</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">partition</span><span class="hljs-params">(<span class="hljs-type">int</span> alist[], <span class="hljs-type">int</span> low, <span class="hljs-type">int</span> high)</span></span>&#123;<br>    <span class="hljs-type">int</span> pivot = alist[low];<br>    <span class="hljs-keyword">while</span> (low &lt; high)&#123;<br>        <span class="hljs-keyword">while</span> (low &lt; high &amp;&amp; alist[high] &gt;= pivot)&#123;<br>            high--;<br>        &#125;<br>        alist[low] = alist[high];<br>        <span class="hljs-keyword">while</span> (low &lt; high &amp;&amp; alist[low] &lt;= pivot)&#123;<br>            low++;<br>        &#125;<br>        alist[high] = alist[low];<br>    &#125;<br>    alist[low] = pivot;<br>    <span class="hljs-keyword">return</span> low;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">quick_sort</span><span class="hljs-params">(<span class="hljs-type">int</span> alist[], <span class="hljs-type">int</span> low, <span class="hljs-type">int</span> high)</span></span>&#123;<br>    <span class="hljs-keyword">if</span> (low &gt;= high) &#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-type">int</span> mid_value = <span class="hljs-built_in">partition</span>(alist, low, high);<br>    <span class="hljs-built_in">quick_sort</span>(alist, low, mid_value<span class="hljs-number">-1</span>);<br>    <span class="hljs-built_in">quick_sort</span>(alist, mid_value+<span class="hljs-number">1</span>, high);<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-type">int</span> alist[] = &#123;<br>            <span class="hljs-number">43</span>, <span class="hljs-number">23</span>, <span class="hljs-number">33</span>, <span class="hljs-number">13</span>, <span class="hljs-number">56</span>, <span class="hljs-number">65</span>, <span class="hljs-number">35</span>, <span class="hljs-number">36</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9</span><br>    &#125;;<br>    <span class="hljs-type">int</span> n = <span class="hljs-built_in">sizeof</span> (alist) / <span class="hljs-built_in">sizeof</span> (alist[<span class="hljs-number">0</span>]);<br>    <span class="hljs-built_in">quick_sort</span>(alist, <span class="hljs-number">0</span>, n - <span class="hljs-number">1</span>);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>        cout &lt;&lt; alist[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    cout &lt;&lt; endl;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度</p><p>最优时间复杂度：O(nlogn)</p><p>最坏时间复杂度：O(n<sup>2</sup>)</p><p>稳定性：不稳定</p><h2 id="归并排序-Merge-Sort"><a href="#归并排序-Merge-Sort" class="headerlink" title="归并排序(Merge Sort)"></a>归并排序(Merge Sort)</h2><p>先递归分解数组，在合并数组。</p><p>将数组分解最小后，然后合并两个有序数组，基本思路是比较两个数组最前面的数，谁小就先取谁，取了之后相应的指针就往后移动一位。然后再比较，直至一个数组为空最后把另一个数组的剩余部分复制过来即可</p><h3 id="过程分析"><a href="#过程分析" class="headerlink" title="过程分析"></a>过程分析</h3><p>​<img src="/assets/image-20240220111402-619ric6.png" alt="image">​</p><h3 id="代码实现-5"><a href="#代码实现-5" class="headerlink" title="代码实现"></a>代码实现</h3><p>‍</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">merge_sort</span>(<span class="hljs-params">alist</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;归并排序&quot;&quot;&quot;</span><br>    n = <span class="hljs-built_in">len</span>(alist)<br>    <span class="hljs-keyword">if</span> n &lt;= <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> alist<br>    mid = n // <span class="hljs-number">2</span><br><br>    <span class="hljs-comment"># left 采用归并排序后形成的有序的新的列表</span><br>    left_li = merge_sort(alist[:mid])<br>    <span class="hljs-comment"># right 采用归并排序后形成的新的有序列表</span><br>    right_li = merge_sort(alist[mid:])<br><br>    <span class="hljs-comment"># 将两个有序的子序列合并为一个新的整体</span><br>    <span class="hljs-comment"># merge(left, right)</span><br>    left_pointer, right_pointer = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>    result = []<br><br>    <span class="hljs-keyword">while</span> left_pointer &lt; <span class="hljs-built_in">len</span>(left_li) <span class="hljs-keyword">and</span> right_pointer &lt; <span class="hljs-built_in">len</span>(right_li):<br>        <span class="hljs-keyword">if</span> left_li[left_pointer] &lt; right_li[right_pointer]:<br>            result.append(left_li[left_pointer])<br>            left_pointer += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            result.append(right_li[right_pointer])<br>            right_pointer += <span class="hljs-number">1</span><br><br>    result += left_li[left_pointer:]<br>    result += right_li[right_pointer:]<br>    <span class="hljs-keyword">return</span> result<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    x1 = [<span class="hljs-number">43</span>, <span class="hljs-number">23</span>, <span class="hljs-number">33</span>, <span class="hljs-number">13</span>, <span class="hljs-number">56</span>, <span class="hljs-number">65</span>, <span class="hljs-number">35</span>, <span class="hljs-number">36</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9</span>]<br>    <span class="hljs-built_in">print</span>(merge_sort(x1))<br></code></pre></td></tr></table></figure><h2 id="堆排序（Haep-Sort）"><a href="#堆排序（Haep-Sort）" class="headerlink" title="堆排序（Haep Sort）"></a>堆排序（Haep Sort）</h2><p>堆必须是一个完全二叉树</p><p>​<img src="/assets/image-20240224100759-9rljked.png" alt="image">​</p><p>堆序性</p><p>小根堆：每个父节点元素小于子节点元素</p><p>大根堆：每个父节点元素大于子节点元素</p><p>​<img src="/assets/image-20240224101014-n4kxjzg.png" alt="image">​</p><p>堆的存储：</p><p>一般用数组来表示，下标为i的节点的父节点下标为(i-1)&#x2F;2；其左右子节点分别为(2i+1),(2i-1)</p><p>堆排序，利用大（小）顶堆堆顶记录最大（小）值，使得每次从无序中选择最大（小）值</p><p>​<img src="/assets/v2-b7907d351809293c60658b0b87053c66_b-20240224104300-yyoyvj8.webp" alt="v2-b7907d351809293c60658b0b87053c66_b">​</p><h3 id="代码实现-6"><a href="#代码实现-6" class="headerlink" title="代码实现"></a>代码实现</h3><p>c++</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;algorithm&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">max_heapify</span><span class="hljs-params">(<span class="hljs-type">int</span> arr[], <span class="hljs-type">int</span> start, <span class="hljs-type">int</span> end)</span> </span>&#123;<br>    <span class="hljs-comment">//建立父节点指标和子节点指标</span><br>    <span class="hljs-type">int</span> dad = start;<br>    <span class="hljs-type">int</span> son = dad * <span class="hljs-number">2</span> + <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">while</span> (son &lt;= end) &#123; <span class="hljs-comment">//若子节点指标在范围内才做比较</span><br>        <span class="hljs-keyword">if</span> (son + <span class="hljs-number">1</span> &lt;= end &amp;&amp; arr[son] &lt; arr[son + <span class="hljs-number">1</span>]) <span class="hljs-comment">//先比较两个子节点大小，选择最大的</span><br>            son++;<br>        <span class="hljs-keyword">if</span> (arr[dad] &gt; arr[son]) <span class="hljs-comment">//如果父节点大于子节点代表调整完毕，直接跳出函数</span><br>            <span class="hljs-keyword">return</span>;<br>        <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">//否则交换父子内容再继续子节点和孙节点比较</span><br>            <span class="hljs-built_in">swap</span>(arr[dad], arr[son]);<br>            dad = son;<br>            son = dad * <span class="hljs-number">2</span> + <span class="hljs-number">1</span>;<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">heap_sort</span><span class="hljs-params">(<span class="hljs-type">int</span> arr[], <span class="hljs-type">int</span> len)</span> </span>&#123;<br>    <span class="hljs-comment">//初始化，i从最后一个父节点开始调整</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = len / <span class="hljs-number">2</span> - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i--)<br>        <span class="hljs-built_in">max_heapify</span>(arr, i, len - <span class="hljs-number">1</span>);<br>    <span class="hljs-comment">//先将第一个元素和已经排好的元素前一位做交换，再从新调整(刚调整的元素之前的元素)，直到排序完毕</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = len - <span class="hljs-number">1</span>; i &gt; <span class="hljs-number">0</span>; i--) &#123;<br>        <span class="hljs-built_in">swap</span>(arr[<span class="hljs-number">0</span>], arr[i]);<br>        <span class="hljs-built_in">max_heapify</span>(arr, <span class="hljs-number">0</span>, i - <span class="hljs-number">1</span>);<br>    &#125;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> arr[] = &#123; <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">8</span>, <span class="hljs-number">6</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">8</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">9</span>, <span class="hljs-number">7</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span> &#125;;<br>    <span class="hljs-type">int</span> len = (<span class="hljs-type">int</span>) <span class="hljs-built_in">sizeof</span>(arr) / <span class="hljs-built_in">sizeof</span>(*arr);<br>    <span class="hljs-built_in">heap_sort</span>(arr, len);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; len; i++)<br>        cout &lt;&lt; arr[i] &lt;&lt; <span class="hljs-string">&#x27; &#x27;</span>;<br>    cout &lt;&lt; endl;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>python</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><br><span class="hljs-function">def <span class="hljs-title">heapify</span><span class="hljs-params">(alist, start, end)</span>:</span><br><span class="hljs-function">    dad =</span> start<br>    son = dad * <span class="hljs-number">2</span> + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> son &lt;= end:<br>        <span class="hljs-keyword">if</span> son + <span class="hljs-number">1</span> &lt;= end <span class="hljs-keyword">and</span> alist[son] &lt; alist[son + <span class="hljs-number">1</span>]:<br>            son += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> alist[dad] &gt; alist[son]:<br>            <span class="hljs-keyword">return</span><br>        <span class="hljs-keyword">else</span>:<br>            alist[dad], alist[son] = alist[son], alist[dad]<br>            dad = son<br>            son = dad * <span class="hljs-number">2</span> + <span class="hljs-number">1</span><br><br><br>def <span class="hljs-built_in">heap_sort</span>(alist, length):<br>    <span class="hljs-keyword">for</span> i in <span class="hljs-built_in">range</span>(length<span class="hljs-comment">//2-1, -1, -1):</span><br>        <span class="hljs-built_in">heapify</span>(alist, i, length<span class="hljs-number">-1</span>)<br>    <span class="hljs-keyword">for</span> i in <span class="hljs-built_in">range</span>(length<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-1</span>):<br>        alist[<span class="hljs-number">0</span>], alist[i] = alist[i], alist[<span class="hljs-number">0</span>]<br>        <span class="hljs-built_in">heapify</span>(alist, <span class="hljs-number">0</span>, i<span class="hljs-number">-1</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    x1 = [<span class="hljs-number">43</span>, <span class="hljs-number">23</span>, <span class="hljs-number">33</span>, <span class="hljs-number">13</span>, <span class="hljs-number">56</span>, <span class="hljs-number">65</span>, <span class="hljs-number">35</span>, <span class="hljs-number">36</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9</span>]<br>    <span class="hljs-built_in">heap_sort</span>(x1, <span class="hljs-built_in">len</span>(x1))<br>    <span class="hljs-built_in">print</span>(x1)<br></code></pre></td></tr></table></figure><h2 id="计数排序-Counting-Sort"><a href="#计数排序-Counting-Sort" class="headerlink" title="计数排序(Counting Sort)"></a>计数排序(Counting Sort)</h2><p>一种稳定的线性时间排序算法</p><p>计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于I的元素的个数</p><p>​<img src="/assets/v2-827d96b8ca3682e8775f4916f22b45ac_b-20240225102446-tgkc9oy.webp" alt="v2-827d96b8ca3682e8775f4916f22b45ac_b">​</p><h3 id="代码实现-7"><a href="#代码实现-7" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">def <span class="hljs-title">counting_sort</span><span class="hljs-params">(alist, max_value)</span>:</span><br><span class="hljs-function">    bucket_len =</span> max_value + <span class="hljs-number">1</span><br>    bucket = [<span class="hljs-number">0</span>] * bucket_len<br>    sorted_index = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i in <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(alist)):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> bucket[alist[i]]:<br>            bucket[alist[i]] = <span class="hljs-number">0</span><br>        bucket[alist[i]] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> j in <span class="hljs-built_in">range</span>(bucket_len):<br>        <span class="hljs-keyword">while</span> bucket[j] &gt; <span class="hljs-number">0</span>:<br>            alist[sorted_index] = j<br>            sorted_index += <span class="hljs-number">1</span><br>            bucket[j] -= <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> alist<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    x1 = [<span class="hljs-number">43</span>, <span class="hljs-number">23</span>, <span class="hljs-number">33</span>, <span class="hljs-number">13</span>, <span class="hljs-number">56</span>, <span class="hljs-number">65</span>, <span class="hljs-number">35</span>, <span class="hljs-number">36</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9</span>]<br>    <span class="hljs-built_in">counting_sort</span>(x1, <span class="hljs-built_in">max</span>(x1))<br>    <span class="hljs-built_in">print</span>(x1)<br></code></pre></td></tr></table></figure><p>时间复杂度：O（n）</p><p>稳定性：稳定</p><h2 id="桶排序-Bucket-Sort"><a href="#桶排序-Bucket-Sort" class="headerlink" title="桶排序(Bucket Sort)"></a>桶排序(Bucket Sort)</h2><p>首先将元素分在不同的桶中，在对每个桶中的元素进行排序</p><h3 id="代码实现-8"><a href="#代码实现-8" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">def <span class="hljs-title">bucket_sort</span><span class="hljs-params">(alist, n=<span class="hljs-number">10</span>, max_number=<span class="hljs-number">1000</span>)</span>:</span><br><span class="hljs-function">    buckets =</span> [[] <span class="hljs-function"><span class="hljs-keyword">for</span> _ in <span class="hljs-title">range</span><span class="hljs-params">(n)</span>]  # 创建桶</span><br><span class="hljs-function">    <span class="hljs-keyword">for</span> var in alist:</span><br><span class="hljs-function">        i =</span> <span class="hljs-built_in">min</span>(var <span class="hljs-comment">// (max_number // n), n - 1)</span><br>        buckets[i].<span class="hljs-built_in">append</span>(var)<br>        <span class="hljs-keyword">for</span> j in <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(buckets[i])<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-1</span>):<br>            <span class="hljs-keyword">if</span> buckets[i][j] &lt; buckets[i][j<span class="hljs-number">-1</span>]:<br>                buckets[i][j], buckets[i][j<span class="hljs-number">-1</span>] = buckets[i][j<span class="hljs-number">-1</span>], buckets[i][j]<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">break</span><br>    sort_alist = []<br>    <span class="hljs-keyword">for</span> buc in buckets:<br>        sort_alist.<span class="hljs-built_in">extend</span>(buc)<br>    <span class="hljs-keyword">return</span> sort_alist<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    x1 = [<span class="hljs-number">43</span>, <span class="hljs-number">23</span>, <span class="hljs-number">33</span>, <span class="hljs-number">13</span>, <span class="hljs-number">56</span>, <span class="hljs-number">65</span>, <span class="hljs-number">35</span>, <span class="hljs-number">36</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9</span>]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">bucket_sort</span>(x1))<br></code></pre></td></tr></table></figure><h2 id="基数排序-Radix-Sort"><a href="#基数排序-Radix-Sort" class="headerlink" title="基数排序(Radix Sort)"></a>基数排序(Radix Sort)</h2><p>属于分配式排序，通过键值的各个位的值，将要排序的元素分配到某些桶中，待到排序的作用</p><p>基本思想：</p><p>将所有待比较数值统一为同样的数位长度，数位较短的前面补0，然后从最低为开始依次进行排序</p><p>​<img src="/assets/36275e6835df49ffb3e60f0cdae96993-20240225212647-nnoeynz.gif" alt="36275e6835df49ffb3e60f0cdae96993">​</p><p>最低有效位优先（LSD）</p><p>最高有效位优先（<em>MSD</em>）</p><h3 id="代码实现-9"><a href="#代码实现-9" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">def <span class="hljs-title">counting_sort</span><span class="hljs-params">(arr, exp)</span>:</span><br><span class="hljs-function">    n =</span> <span class="hljs-built_in">len</span>(arr)<br>    output = [<span class="hljs-number">0</span>] * n<br>    count = [<span class="hljs-number">0</span>] * <span class="hljs-number">10</span><br><br>    <span class="hljs-keyword">for</span> i in <span class="hljs-built_in">range</span>(n):<br>        index = arr[i] <span class="hljs-comment">// exp</span><br>        count[index % <span class="hljs-number">10</span>] += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">for</span> i in <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>):<br>        count[i] += count[i - <span class="hljs-number">1</span>]<br><br>    i = n - <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> i &gt;= <span class="hljs-number">0</span>:<br>        index = arr[i] <span class="hljs-comment">// exp</span><br>        output[count[index % <span class="hljs-number">10</span>] - <span class="hljs-number">1</span>] = arr[i]<br>        count[index % <span class="hljs-number">10</span>] -= <span class="hljs-number">1</span><br>        i -= <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">for</span> i in <span class="hljs-built_in">range</span>(n):<br>        arr[i] = output[i]<br><br><br>def <span class="hljs-built_in">radix_sort</span>(arr):<br>    max_element = <span class="hljs-built_in">max</span>(arr)<br>    exp = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> max_element <span class="hljs-comment">// exp &gt; 0:</span><br>        <span class="hljs-built_in">counting_sort</span>(arr, exp)<br>        exp *= <span class="hljs-number">10</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    x1 = [<span class="hljs-number">43</span>, <span class="hljs-number">23</span>, <span class="hljs-number">33</span>, <span class="hljs-number">13</span>, <span class="hljs-number">56</span>, <span class="hljs-number">65</span>, <span class="hljs-number">35</span>, <span class="hljs-number">36</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9</span>]<br>    <span class="hljs-built_in">radix_sort</span>(x1)<br>    <span class="hljs-built_in">print</span>(x1)<br></code></pre></td></tr></table></figure><h2 id="双调排序-Bitonic-Sort"><a href="#双调排序-Bitonic-Sort" class="headerlink" title="双调排序(Bitonic Sort)"></a>双调排序(Bitonic Sort)</h2><p>即双向冒泡排序</p><h2 id="猴子排序-Bogo-Sort"><a href="#猴子排序-Bogo-Sort" class="headerlink" title="猴子排序(Bogo Sort)"></a>猴子排序(Bogo Sort)</h2><p>赌狗真神</p><p>代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">import</span> random</span><br><span class="hljs-function"></span><br><span class="hljs-function"></span><br><span class="hljs-function">def <span class="hljs-title">is_sorted</span><span class="hljs-params">(data)</span>:</span><br><span class="hljs-function">    <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;检查列表是否已经排序&quot;</span><span class="hljs-string">&quot;&quot;</span></span><br><span class="hljs-function">    for i in range(len(data) - <span class="hljs-number">1</span>):</span><br><span class="hljs-function">        if data[i] &gt; data[i + <span class="hljs-number">1</span>]:</span><br><span class="hljs-function">            return False</span><br><span class="hljs-function">    return True</span><br><span class="hljs-function"></span><br><span class="hljs-function"></span><br><span class="hljs-function">def bogo_sort(data):</span><br><span class="hljs-function">    <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;猴子排序&quot;</span><span class="hljs-string">&quot;&quot;</span></span><br><span class="hljs-function">    while not is_sorted(data):</span><br><span class="hljs-function">        random.shuffle(data)</span><br><span class="hljs-function">    return data</span><br><span class="hljs-function"></span><br><span class="hljs-function"></span><br><span class="hljs-function">if __name__ =</span>= <span class="hljs-string">&quot;__main__&quot;</span>:<br>    x1 = [<span class="hljs-number">35</span>, <span class="hljs-number">36</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9</span>]<br>    <span class="hljs-built_in">bogo_sort</span>(x1)<br>    <span class="hljs-built_in">print</span>(x1)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>卷积神经网络（CNN）简单介绍</title>
    <link href="/2024/06/19/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2024/06/19/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<p>作用：分类与检索，超分辨率重构， 医学任务</p><p>整体架构：输入层，卷积层，池化层，全连接层</p><p>卷积层涉及的参数：滑动窗口步长，卷积核尺寸，边缘填充，卷积核个数</p><p>步长越小特征值越多，计算效率低，可能会造成过拟合</p><p>填充：让边界多被利用</p><p>卷积结构计算公式：(先pass)</p><p>卷积参数共享：</p><p>池化层：下采样，压缩特征，防止过拟合</p><p>最大池化：选取最大值？</p><p>感受野：</p><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><h3 id="基本属性"><a href="#基本属性" class="headerlink" title="基本属性"></a>基本属性</h3><p>功能：提取图像特征</p><p>卷积核大小(kernel)：一个滤波矩阵，在达到相同感受野的情况下，卷积核越小，参数和计算量越小</p><p>卷积核数目：数目越多计算量越大，模型拟合能力越强</p><p>步长：卷积核遍历时移动的像素</p><p>填充：处理特征图边界</p><p>通道：卷积层的通道数</p><p>激活函数：一般为RELU</p><p>反卷积</p><p>可分离卷积</p><p>分组卷积</p><h3 id="卷积的三种模式"><a href="#卷积的三种模式" class="headerlink" title="卷积的三种模式"></a>卷积的三种模式</h3><p>full mode：从卷积核和图像相交时开始做卷积，空白部分填0</p><p>same mode：当卷积核中兴与图像边角重合时，开始做卷积运算，空白部分填0</p><p>valid mode：当卷积核全部在图像里面时，进行卷积运算</p><h3 id="本质"><a href="#本质" class="headerlink" title="本质"></a>本质</h3><p>卷积连续形式：$(f * g)(t) &#x3D; \int_{-\infty}^{+\infty}f(\tau)\cdot g(t - \tau)\mathop{}!\mathrm{d}\tau$</p><p>卷积离散形式：$(x * y)[n] &#x3D; \sum_{m &#x3D; -\infty}^{+\infty}x[m]\cdot y[n - m]$</p><p>转置卷积(反卷积)：</p><p>深度可分离卷积</p><p>3D卷积</p><p>空洞卷积</p><p>‍</p><h2 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h2><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>增大网络感受野</p><p>抑制噪声，降低信息冗余</p><p>降低模型计算量，降低网络优化难度，防止网络过拟合</p><h3 id="Max-Pooling-最大池化"><a href="#Max-Pooling-最大池化" class="headerlink" title="Max Pooling(最大池化)"></a>Max Pooling(最大池化)</h3><p>将图像划分为若干个区域，每个区域输出最大值</p><p>$y_{k i j}&#x3D;\max _ {(p, q) \in \mathcal{R}<em>{i j}} x</em>{k p q}$</p><h3 id="Average-Pooling-平均池化"><a href="#Average-Pooling-平均池化" class="headerlink" title="Average Pooling(平均池化)"></a>Average Pooling(平均池化)</h3><p>将图像划分为若干个区域，每个区域输出平均值</p><p>$y_{k i j}&#x3D;\frac{1}{\left|\mathcal{R}_ {i j}\right|} \sum {(p, q) \in \mathcal{R}_ {i j}} x_{k p q}$</p><h3 id="Global-Average-Pooling-全局平均池化"><a href="#Global-Average-Pooling-全局平均池化" class="headerlink" title="Global Average Pooling(全局平均池化)"></a>Global Average Pooling(全局平均池化)</h3><p>取代全连接层，减少过拟合</p><p>不划分区域，将整个特征图中的所有元素平均输出到下一层</p><p>$y_{k}&#x3D;\frac{1}{\left|\mathcal{R}\right|} \sum_{(p, q) \in \mathcal{R}} x_{k p q}$</p><p>最为全连接层的替代，对整个网络在结构上做正则化防止过拟合，删除了全连接层中的黑箱问题</p><h3 id="Mix-Pooling-混合池化"><a href="#Mix-Pooling-混合池化" class="headerlink" title="Mix Pooling(混合池化)"></a>Mix Pooling(混合池化)</h3><p>在训练期间随机采用最大池化和平均池化</p><p>$y_{k i j}&#x3D;\lambda \cdot \max _ {(p, q) \in \mathcal{R} {i j}} x_{k p q}+(1-\lambda) \cdot \frac{1}{\left|\mathcal{R}_ {i j}\right|} \sum {(p, q) \in \mathcal{R}_ {i j}} x_{k p q}$</p><p>一定程度上解决了过拟合问题，所需要的计算开销可忽略不计，无需任何超参数调整</p><h3 id="Stochastic-Pooling-随机池化"><a href="#Stochastic-Pooling-随机池化" class="headerlink" title="Stochastic Pooling(随机池化)"></a>Stochastic Pooling(随机池化)</h3><p>先将方格中的元素同时除以他们的和，得到概率矩阵，按照概率随机选择方格，得到的值就是方格位置的值</p><p>具有更大的泛化能力</p><h3 id="Power-Average-Polling-幂平均池化"><a href="#Power-Average-Polling-幂平均池化" class="headerlink" title="Power Average Polling(幂平均池化)"></a>Power Average Polling(幂平均池化)</h3><p>基于平均池化和最大池化的结合，利用p来确定相对重要性，p&#x3D;1，局部求和；p趋于无穷，最大池化</p><p>$\tilde{\mathbf{a}}&#x3D;\sqrt[p]{\sum_{i \in \mathbf{R}} \mathbf{a}_{i}^{p}}$</p><h3 id="Detail-Preserving-Pooling-DPP池化"><a href="#Detail-Preserving-Pooling-DPP池化" class="headerlink" title="Detail-Preserving Pooling(DPP池化)"></a>Detail-Preserving Pooling(DPP池化)</h3><p>一种自适应的池化方法，放大空间变化并保留重要的图像细节，且内部参数可以通过反向传播加以学习</p><p>$O[p]&#x3D;\frac{1}{k_{p}} \sum_{q \in \Omega_{p}} I[q] \cdot|I[q]-\tilde{I}[p]|^{\lambda}$</p><h3 id="Local-Importance-Pooling-局部重要性池化"><a href="#Local-Importance-Pooling-局部重要性池化" class="headerlink" title="Local Importance Pooling(局部重要性池化)"></a>Local Importance Pooling(局部重要性池化)</h3><p>输入学习自适应重要性权重，LIP可以在下采样中自动增加特征判别功能</p><p>$O_{x^{\prime}, y^{\prime}}&#x3D;\frac{\sum_{(\Delta x, \Delta y) \in \Omega} F(I)_ {x+\Delta x, y+\Delta y} I_{x+\Delta x, y+\Delta y}}{\sum_{(\Delta x, \Delta y) \in \Omega} F(I)_{x+\Delta x, y+\Delta y}}$</p><p>可以极大保留物体大部分细节</p><h3 id="Soft-Pooling-软池化"><a href="#Soft-Pooling-软池化" class="headerlink" title="Soft Pooling(软池化)"></a>Soft Pooling(软池化)</h3><p>基于softmax加权的方法来保留输入的基本属性，同时放大更大强度的特征激活。softpool是可微的，所以在反向传播中为每个输入获得一个梯度吗，有利于提高训练效果</p><p>计算流程：</p><ol><li>特征图透过滑动视窗来框选局部数值</li><li>框选的局部数值会先经过指数计算，计算出的值为对应的特征数值的权重</li><li>将各自的特征数值与其相对应的权重相乘</li><li>最后进行加总</li></ol><h2 id="全连接"><a href="#全连接" class="headerlink" title="全连接"></a>全连接</h2><p>‍</p><h2 id="上采样和下采样的区别"><a href="#上采样和下采样的区别" class="headerlink" title="上采样和下采样的区别"></a>上采样和下采样的区别</h2><p>上采样：增大信号（图片放大）</p><p>常见算法：双线性插值，转置卷积，上池化，上采样</p><p>下采样：pass</p><h2 id="常用架构"><a href="#常用架构" class="headerlink" title="常用架构"></a>常用架构</h2><h3 id="LeNet-5架构"><a href="#LeNet-5架构" class="headerlink" title="LeNet-5架构"></a>LeNet-5架构</h3><p>C1，卷积层<br>S2，池化层<br>C3，卷积层<br>S4，池化层<br>C5，卷积层<br>F6，全连接层<br>OUTPUT，全连接层</p><h3 id="AlexNet架构"><a href="#AlexNet架构" class="headerlink" title="AlexNet架构"></a>AlexNet架构</h3><ul><li>整体结构上与LeNet-5类似</li><li>包含5个卷积层和3个全连接层</li><li>使用ReLU非线性激活函数</li><li>使用了Data Augmentation，Dropout，Momentum，Weight Decay 等策略改进训练</li><li>在算力有限的情况下，将模型划分为两个部分</li><li>增加局部响应归一化</li></ul><h3 id="VGGNet架构"><a href="#VGGNet架构" class="headerlink" title="VGGNet架构"></a>VGGNet架构</h3><ul><li>网络层级更深，从8层增加到16层和19层</li><li>仅用3*3大小的卷积进行串联叠加，减小参数个数</li><li>卷积采样的步长为1<em>1，maxpooling的步长为2</em>2*</li><li>去掉了效果相应提升不明显的LRM(归一化)</li><li>增加了特征图的个数</li></ul><h3 id="Network-in-Network-NIN-架构"><a href="#Network-in-Network-NIN-架构" class="headerlink" title="Network in Network(NIN)架构"></a>Network in Network(NIN)架构</h3><ul><li>利用多层的全连接网络替换线性的卷积，其中卷积层为线性的操作，MLP为非线性的操作，因此具有更强的抽象能力</li><li>去掉了全连接层，使用GlobalAveragePooling</li><li>简化网络结构，仅包含4个NIN单元和一个GAP</li></ul><h3 id="GooLeNet架构"><a href="#GooLeNet架构" class="headerlink" title="GooLeNet架构"></a>GooLeNet架构</h3><p>Inception：在同一层利用不同大小的卷积核提取不同特征</p><ul><li>某一层有多个不同大小卷积核，使网络在每一层都能学到不同尺度的特征，通过滤波器拼接为多个特征图</li><li>增加了计算量</li></ul><p>InceptionV3</p><h3 id="Deep-Resdual-Net架构"><a href="#Deep-Resdual-Net架构" class="headerlink" title="Deep Resdual Net架构"></a>Deep Resdual Net架构</h3><p>新的神经网络不在拟合原始的映射关系，而是$\mathcal{F} \left(\mathbf{x}\right) &#x3D; \mathcal{H} \left(\mathbf{x}\right) - \mathbf{x}$</p><p>减少梯度弥散问题</p><h3 id="Identity-Mapping-Residual-Net架构"><a href="#Identity-Mapping-Residual-Net架构" class="headerlink" title="Identity Mapping Residual Net架构"></a>Identity Mapping Residual Net架构</h3><p>在原始的ResNet架构上，激活函数又ReLU替换为一个恒定映射$\mathbb{x}<em>{\ell+1} &#x3D; \mathbb{x}</em>{\ell} + \mathcal{F} \left(\mathbb{x}<em>{\ell}, \mathcal{W}</em>{\ell}\right)$，对于任意深度的单元L，有$\mathbb{x}<em>L &#x3D; \mathbb{x}</em>{\ell} + \sum_{i&#x3D;\ell}^{L-1}{\mathcal{F} \left(\mathbb{x}_i, \mathcal{W}_i\right)}$</p><p>确保在权重很小的时候也不会出现梯度弥散</p><h3 id="DenseNet架构"><a href="#DenseNet架构" class="headerlink" title="DenseNet架构"></a>DenseNet架构</h3><ul><li>将网络中每一层都与其后序层进行直接连接</li><li>网络的增长率（？）</li><li>在3<em>3的卷积之前增加1</em>1 的卷积进行降维操作*</li><li>在两个DenseBlock之间增加过渡层，进一步减少特征图的个数</li></ul><h3 id="R-CNN架构"><a href="#R-CNN架构" class="headerlink" title="R-CNN架构"></a>R-CNN架构</h3><p>RCNN用于目标检测的流程：</p><ol><li>输入图像</li><li>利用Selective Search (fast mode)提取大约2000个左右的region proposal</li><li>对于每一个region proposal我们先将其resize成227x227输入ImageNet图像分<br> 类网络</li><li>将提取到的每个region proposal的特征输入SVM分类器进行分类</li></ol><p>缺点1：需要保留大量的中间特征， 5K图像数百G特征文件<br>缺点2：每个region proposal单独处理，速度慢，GPU上47s&#x2F;张图像</p><h3 id="SPP-Net架构"><a href="#SPP-Net架构" class="headerlink" title="SPP-Net架构"></a>SPP-Net架构</h3><ul><li>CNN经典结构要求固定尺寸的输入图像，可能损失信息</li><li>利用Spatial Pyramid Pooling （SPP），任意尺寸的响应图可以得到等长的特征</li><li>多层次Pooling: 对形变的鲁棒性</li></ul><h3 id="Fast-R-CNN架构"><a href="#Fast-R-CNN架构" class="headerlink" title="Fast R-CNN架构"></a>Fast R-CNN架构</h3><ul><li>利用Spatial Pyramid Pooling （SPP）进行加速，整张图像只需要通过卷积网络一次</li><li>分类+窗口回归在统一框架中训练，不需要保留中间结果</li><li>速度从RCNN的46s加速到2~3s（主要时间花在region proposal)</li></ul><h3 id="Faster-R-CNN架构"><a href="#Faster-R-CNN架构" class="headerlink" title="Faster R-CNN架构"></a>Faster R-CNN架构</h3><ul><li>Faster R-CNN = RPN + Fast R-CNN</li><li>用RPN网络代替Edge box等Region Proposal 方法，共享了RPN和</li><li>Fast R-CNN卷积层参数，支持端到端训练</li><li>速度显著提高，GPU 200ms &#x2F;张图像</li></ul><h3 id="FCN架构"><a href="#FCN架构" class="headerlink" title="FCN架构"></a>FCN架构</h3><p>结构特点：</p><ul><li>支持任意长宽比图像，使用1x1卷积核替代全连接保持空间关系</li><li>利用反卷积层进行上采样</li><li>对输入图像的每个像素进行分类（Softmax Loss）</li></ul><h3 id="End-to-End图像对齐网络ST-Net"><a href="#End-to-End图像对齐网络ST-Net" class="headerlink" title="End to End图像对齐网络ST-Net"></a>End to End图像对齐网络ST-Net</h3><p>通过子网络估计图像仿射变换参数，端到端的完成图像校正</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="leNet-5架构"><a href="#leNet-5架构" class="headerlink" title="leNet-5架构"></a>leNet-5架构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入torch库</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn  <span class="hljs-comment"># 导入神经网络的包</span><br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> option  <span class="hljs-comment"># 包含各种优化算法</span><br><span class="hljs-keyword">import</span> torchvision  <span class="hljs-comment"># pytorch中的视觉库，提供一些</span><br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms  <span class="hljs-comment"># 用于对图像进行预处理和转换模块</span><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader  <span class="hljs-comment"># 加载数据库</span><br><br><br><span class="hljs-comment"># 定义LeNet-5架构的CNN</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LeNet5</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(LeNet5, self).__init__()  <span class="hljs-comment"># 继承nn.Module基类，初始化父类</span><br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">5</span>)  <span class="hljs-comment"># 第一个卷积层，输入通道数1，输出通道数6，卷积核大小5x5</span><br>        self.pool1 = nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)  <span class="hljs-comment"># 第一个池化层，最大池化，池化核大小2x2，步长2</span><br>        self.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">5</span>)  <span class="hljs-comment"># 第二个卷积层，输入通道数6，输出通道数16，卷积核大小5x5</span><br>        self.pool2 = nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)  <span class="hljs-comment"># 第二个池化层，最大池化，池化核大小2x2，步长2</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">4</span> * <span class="hljs-number">4</span>, <span class="hljs-number">120</span>)  <span class="hljs-comment"># 全连接层，输入维度16*4*4（经过前两层卷积和池化后的输出），输出维度120</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)  <span class="hljs-comment"># 全连接层，输入维度120，输出维度84</span><br>        self.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)  <span class="hljs-comment"># 全连接层，输入维度84，输出维度10（对应MNIST的10个类别）</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 前向传播函数</span><br>        x = self.pool1(torch.relu(self.conv1(x)))  <span class="hljs-comment"># 第一个卷积+ReLU激活+池化操作</span><br>        x = self.pool2(torch.relu(self.conv2(x)))  <span class="hljs-comment"># 第二个卷积+ReLU激活+池化操作</span><br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">16</span> * <span class="hljs-number">4</span> * <span class="hljs-number">4</span>)  <span class="hljs-comment"># 将卷积后得到的特征图展平为一维向量</span><br>        x = torch.relu(self.fc1(x))  <span class="hljs-comment"># 通过第一个全连接层并应用ReLU激活</span><br>        x = torch.relu(self.fc2(x))  <span class="hljs-comment"># 通过第二个全连接层并应用ReLU激活</span><br>        x = self.fc3(x)  <span class="hljs-comment"># 通过第三个全连接层（输出层）</span><br>        <span class="hljs-keyword">return</span> x  <span class="hljs-comment"># 返回前向传播结果</span><br><br><br><span class="hljs-comment"># 定义数据变换和加载MNIST数据集，数据预处理</span><br>transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="hljs-number">0.5</span>,), (<span class="hljs-number">0.5</span>,))])<br><br><span class="hljs-comment"># 调整数据集</span><br>train_dataset = torchvision.datasets.MNIST(<span class="hljs-string">&#x27;./CNN&#x27;</span>, train=<span class="hljs-literal">True</span>, transform=transform, download=<span class="hljs-literal">False</span>)<br>train_loader = DataLoader(train_dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 测试数据集</span><br>test_dataset = torchvision.datasets.MNIST(<span class="hljs-string">&#x27;./CNN&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=transform, download=<span class="hljs-literal">False</span>)<br>test_loader = DataLoader(test_dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">False</span>)<br><br><br><span class="hljs-comment"># 初始化LeNet-5模型，定义损失函数和优化器</span><br>net = LeNet5()  <span class="hljs-comment"># 创建LeNet5模型实例</span><br>criterion = nn.CrossEntropyLoss()  <span class="hljs-comment"># 使用交叉熵损失函数作为分类任务的损失函数</span><br>optimizer = option.Adam(net.parameters(), lr=<span class="hljs-number">0.001</span>)  <span class="hljs-comment"># 使用Adam优化器，学习率设置为0.001</span><br><br><span class="hljs-comment"># 循环训练</span><br><span class="hljs-keyword">for</span> enoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):  <span class="hljs-comment"># 调整训练的轮数</span><br>    running_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i, date <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader, <span class="hljs-number">0</span>):<br>        inputs, labels = date  <span class="hljs-comment"># 解压当前批次的数据和标签</span><br>        optimizer.zero_grad()  <span class="hljs-comment"># 梯度清零，准备进行新的反向传播计算</span><br><br>        outputs = net(inputs)  <span class="hljs-comment"># 前向传播，计算模型输出</span><br>        loss = criterion(outputs, labels)  <span class="hljs-comment"># 计算损失，根据模型输出与真实标签之间的差异</span><br>        loss.backward()  <span class="hljs-comment"># 反向传播，计算梯度</span><br>        optimizer.step()  <span class="hljs-comment"># 根据梯度更新模型参数</span><br><br>        running_loss += loss.item()  <span class="hljs-comment"># 累加当前批次的损失值</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch:<span class="hljs-subst">&#123;enoch&#125;</span>, loss:<span class="hljs-subst">&#123;running_loss/<span class="hljs-built_in">len</span>(train_loader)&#125;</span>&quot;</span>)  <span class="hljs-comment"># 输出当前训练轮次的平均损失值</span><br></code></pre></td></tr></table></figure><h3 id="github-numpy实现"><a href="#github-numpy实现" class="headerlink" title="github numpy实现"></a>github numpy实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pickle<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CNN</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, conv1_get, size_p1, bp_num1, bp_num2, bp_num3, rate_w=<span class="hljs-number">0.2</span>, rate_t=<span class="hljs-number">0.2</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param conv1_get: [a,c,d], size, number, step of convolution kernel</span><br><span class="hljs-string">        :param size_p1: pooling size</span><br><span class="hljs-string">        :param bp_num1: units number of flatten layer</span><br><span class="hljs-string">        :param bp_num2: units number of hidden layer</span><br><span class="hljs-string">        :param bp_num3: units number of output layer</span><br><span class="hljs-string">        :param rate_w: rate of weight learning</span><br><span class="hljs-string">        :param rate_t: rate of threshold learning</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.num_bp1 = bp_num1<br>        self.num_bp2 = bp_num2<br>        self.num_bp3 = bp_num3<br>        self.conv1 = conv1_get[:<span class="hljs-number">2</span>]<br>        self.step_conv1 = conv1_get[<span class="hljs-number">2</span>]<br>        self.size_pooling1 = size_p1<br>        self.rate_weight = rate_w<br>        self.rate_thre = rate_t<br>        rng = np.random.default_rng()<br>        self.w_conv1 = [<br>            np.asmatrix(-<span class="hljs-number">1</span> * rng.random((self.conv1[<span class="hljs-number">0</span>], self.conv1[<span class="hljs-number">0</span>])) + <span class="hljs-number">0.5</span>)<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.conv1[<span class="hljs-number">1</span>])<br>        ]<br>        self.wkj = np.asmatrix(-<span class="hljs-number">1</span> * rng.random((self.num_bp3, self.num_bp2)) + <span class="hljs-number">0.5</span>)<br>        self.vji = np.asmatrix(-<span class="hljs-number">1</span> * rng.random((self.num_bp2, self.num_bp1)) + <span class="hljs-number">0.5</span>)<br>        self.thre_conv1 = -<span class="hljs-number">2</span> * rng.random(self.conv1[<span class="hljs-number">1</span>]) + <span class="hljs-number">1</span><br>        self.thre_bp2 = -<span class="hljs-number">2</span> * rng.random(self.num_bp2) + <span class="hljs-number">1</span><br>        self.thre_bp3 = -<span class="hljs-number">2</span> * rng.random(self.num_bp3) + <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save_model</span>(<span class="hljs-params">self, save_path</span>):<br>        <span class="hljs-comment"># save model dict with pickle</span><br>        model_dic = &#123;<br>            <span class="hljs-string">&quot;num_bp1&quot;</span>: self.num_bp1,<br>            <span class="hljs-string">&quot;num_bp2&quot;</span>: self.num_bp2,<br>            <span class="hljs-string">&quot;num_bp3&quot;</span>: self.num_bp3,<br>            <span class="hljs-string">&quot;conv1&quot;</span>: self.conv1,<br>            <span class="hljs-string">&quot;step_conv1&quot;</span>: self.step_conv1,<br>            <span class="hljs-string">&quot;size_pooling1&quot;</span>: self.size_pooling1,<br>            <span class="hljs-string">&quot;rate_weight&quot;</span>: self.rate_weight,<br>            <span class="hljs-string">&quot;rate_thre&quot;</span>: self.rate_thre,<br>            <span class="hljs-string">&quot;w_conv1&quot;</span>: self.w_conv1,<br>            <span class="hljs-string">&quot;wkj&quot;</span>: self.wkj,<br>            <span class="hljs-string">&quot;vji&quot;</span>: self.vji,<br>            <span class="hljs-string">&quot;thre_conv1&quot;</span>: self.thre_conv1,<br>            <span class="hljs-string">&quot;thre_bp2&quot;</span>: self.thre_bp2,<br>            <span class="hljs-string">&quot;thre_bp3&quot;</span>: self.thre_bp3,<br>        &#125;<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(save_path, <span class="hljs-string">&quot;wb&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            pickle.dump(model_dic, f)<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Model saved: <span class="hljs-subst">&#123;save_path&#125;</span>&quot;</span>)<br><br><span class="hljs-meta">    @classmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">read_model</span>(<span class="hljs-params">cls, model_path</span>):<br>        <span class="hljs-comment"># read saved model</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(model_path, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            model_dic = pickle.load(f)  <span class="hljs-comment"># noqa: S301</span><br><br>        conv_get = model_dic.get(<span class="hljs-string">&quot;conv1&quot;</span>)<br>        conv_get.append(model_dic.get(<span class="hljs-string">&quot;step_conv1&quot;</span>))<br>        size_p1 = model_dic.get(<span class="hljs-string">&quot;size_pooling1&quot;</span>)<br>        bp1 = model_dic.get(<span class="hljs-string">&quot;num_bp1&quot;</span>)<br>        bp2 = model_dic.get(<span class="hljs-string">&quot;num_bp2&quot;</span>)<br>        bp3 = model_dic.get(<span class="hljs-string">&quot;num_bp3&quot;</span>)<br>        r_w = model_dic.get(<span class="hljs-string">&quot;rate_weight&quot;</span>)<br>        r_t = model_dic.get(<span class="hljs-string">&quot;rate_thre&quot;</span>)<br>        <span class="hljs-comment"># create model instance</span><br>        conv_ins = CNN(conv_get, size_p1, bp1, bp2, bp3, r_w, r_t)<br>        <span class="hljs-comment"># modify model parameter</span><br>        conv_ins.w_conv1 = model_dic.get(<span class="hljs-string">&quot;w_conv1&quot;</span>)<br>        conv_ins.wkj = model_dic.get(<span class="hljs-string">&quot;wkj&quot;</span>)<br>        conv_ins.vji = model_dic.get(<span class="hljs-string">&quot;vji&quot;</span>)<br>        conv_ins.thre_conv1 = model_dic.get(<span class="hljs-string">&quot;thre_conv1&quot;</span>)<br>        conv_ins.thre_bp2 = model_dic.get(<span class="hljs-string">&quot;thre_bp2&quot;</span>)<br>        conv_ins.thre_bp3 = model_dic.get(<span class="hljs-string">&quot;thre_bp3&quot;</span>)<br>        <span class="hljs-keyword">return</span> conv_ins<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sig</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-<span class="hljs-number">1</span> * x))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">do_round</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">round</span>(x, <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">convolute</span>(<span class="hljs-params">self, data, convs, w_convs, thre_convs, conv_step</span>):<br>        <span class="hljs-comment"># convolution process</span><br>        size_conv = convs[<span class="hljs-number">0</span>]<br>        num_conv = convs[<span class="hljs-number">1</span>]<br>        size_data = np.shape(data)[<span class="hljs-number">0</span>]<br>        <span class="hljs-comment"># get the data slice of original image data, data_focus</span><br>        data_focus = []<br>        <span class="hljs-keyword">for</span> i_focus <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, size_data - size_conv + <span class="hljs-number">1</span>, conv_step):<br>            <span class="hljs-keyword">for</span> j_focus <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, size_data - size_conv + <span class="hljs-number">1</span>, conv_step):<br>                focus = data[<br>                    i_focus : i_focus + size_conv, j_focus : j_focus + size_conv<br>                ]<br>                data_focus.append(focus)<br>        <span class="hljs-comment"># calculate the feature map of every single kernel, and saved as list of matrix</span><br>        data_featuremap = []<br>        size_feature_map = <span class="hljs-built_in">int</span>((size_data - size_conv) / conv_step + <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">for</span> i_map <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_conv):<br>            featuremap = []<br>            <span class="hljs-keyword">for</span> i_focus <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data_focus)):<br>                net_focus = (<br>                    np.<span class="hljs-built_in">sum</span>(np.multiply(data_focus[i_focus], w_convs[i_map]))<br>                    - thre_convs[i_map]<br>                )<br>                featuremap.append(self.sig(net_focus))<br>            featuremap = np.asmatrix(featuremap).reshape(<br>                size_feature_map, size_feature_map<br>            )<br>            data_featuremap.append(featuremap)<br><br>        <span class="hljs-comment"># expanding the data slice to One dimenssion</span><br>        focus1_list = []<br>        <span class="hljs-keyword">for</span> each_focus <span class="hljs-keyword">in</span> data_focus:<br>            focus1_list.extend(self.Expand_Mat(each_focus))<br>        focus_list = np.asarray(focus1_list)<br>        <span class="hljs-keyword">return</span> focus_list, data_featuremap<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pooling</span>(<span class="hljs-params">self, featuremaps, size_pooling, pooling_type=<span class="hljs-string">&quot;average_pool&quot;</span></span>):<br>        <span class="hljs-comment"># pooling process</span><br>        size_map = <span class="hljs-built_in">len</span>(featuremaps[<span class="hljs-number">0</span>])<br>        size_pooled = <span class="hljs-built_in">int</span>(size_map / size_pooling)<br>        featuremap_pooled = []<br>        <span class="hljs-keyword">for</span> i_map <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(featuremaps)):<br>            feature_map = featuremaps[i_map]<br>            map_pooled = []<br>            <span class="hljs-keyword">for</span> i_focus <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, size_map, size_pooling):<br>                <span class="hljs-keyword">for</span> j_focus <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, size_map, size_pooling):<br>                    focus = feature_map[<br>                        i_focus : i_focus + size_pooling,<br>                        j_focus : j_focus + size_pooling,<br>                    ]<br>                    <span class="hljs-keyword">if</span> pooling_type == <span class="hljs-string">&quot;average_pool&quot;</span>:<br>                        <span class="hljs-comment"># average pooling</span><br>                        map_pooled.append(np.average(focus))<br>                    <span class="hljs-keyword">elif</span> pooling_type == <span class="hljs-string">&quot;max_pooling&quot;</span>:<br>                        <span class="hljs-comment"># max pooling</span><br>                        map_pooled.append(np.<span class="hljs-built_in">max</span>(focus))<br>            map_pooled = np.asmatrix(map_pooled).reshape(size_pooled, size_pooled)<br>            featuremap_pooled.append(map_pooled)<br>        <span class="hljs-keyword">return</span> featuremap_pooled<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_expand</span>(<span class="hljs-params">self, data</span>):<br>        <span class="hljs-comment"># expanding three dimension data to one dimension list</span><br>        data_expanded = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)):<br>            shapes = np.shape(data[i])<br>            data_listed = data[i].reshape(<span class="hljs-number">1</span>, shapes[<span class="hljs-number">0</span>] * shapes[<span class="hljs-number">1</span>])<br>            data_listed = data_listed.getA().tolist()[<span class="hljs-number">0</span>]<br>            data_expanded.extend(data_listed)<br>        data_expanded = np.asarray(data_expanded)<br>        <span class="hljs-keyword">return</span> data_expanded<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_expand_mat</span>(<span class="hljs-params">self, data_mat</span>):<br>        <span class="hljs-comment"># expanding matrix to one dimension list</span><br>        data_mat = np.asarray(data_mat)<br>        shapes = np.shape(data_mat)<br>        data_expanded = data_mat.reshape(<span class="hljs-number">1</span>, shapes[<span class="hljs-number">0</span>] * shapes[<span class="hljs-number">1</span>])<br>        <span class="hljs-keyword">return</span> data_expanded<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_calculate_gradient_from_pool</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, out_map, pd_pool, num_map, size_map, size_pooling</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        calculate the gradient from the data slice of pool layer</span><br><span class="hljs-string">        pd_pool: list of matrix</span><br><span class="hljs-string">        out_map: the shape of data slice(size_map*size_map)</span><br><span class="hljs-string">        return: pd_all: list of matrix, [num, size_map, size_map]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        pd_all = []<br>        i_pool = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i_map <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_map):<br>            pd_conv1 = np.ones((size_map, size_map))<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, size_map, size_pooling):<br>                <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, size_map, size_pooling):<br>                    pd_conv1[i : i + size_pooling, j : j + size_pooling] = pd_pool[<br>                        i_pool<br>                    ]<br>                    i_pool = i_pool + <span class="hljs-number">1</span><br>            pd_conv2 = np.multiply(<br>                pd_conv1, np.multiply(out_map[i_map], (<span class="hljs-number">1</span> - out_map[i_map]))<br>            )<br>            pd_all.append(pd_conv2)<br>        <span class="hljs-keyword">return</span> pd_all<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, patterns, datas_train, datas_teach, n_repeat, error_accuracy, draw_e=<span class="hljs-built_in">bool</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-comment"># model training</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;----------------------Start Training-------------------------&quot;</span>)<br>        <span class="hljs-built_in">print</span>((<span class="hljs-string">&quot; - - Shape: Train_Data  &quot;</span>, np.shape(datas_train)))<br>        <span class="hljs-built_in">print</span>((<span class="hljs-string">&quot; - - Shape: Teach_Data  &quot;</span>, np.shape(datas_teach)))<br>        rp = <span class="hljs-number">0</span><br>        all_mse = []<br>        mse = <span class="hljs-number">10000</span><br>        <span class="hljs-keyword">while</span> rp &lt; n_repeat <span class="hljs-keyword">and</span> mse &gt;= error_accuracy:<br>            error_count = <span class="hljs-number">0</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;-------------Learning Time <span class="hljs-subst">&#123;rp&#125;</span>--------------&quot;</span>)<br>            <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(datas_train)):<br>                <span class="hljs-comment"># print(&#x27;------------Learning Image: %d--------------&#x27;%p)</span><br>                data_train = np.asmatrix(datas_train[p])<br>                data_teach = np.asarray(datas_teach[p])<br>                data_focus1, data_conved1 = self.convolute(<br>                    data_train,<br>                    self.conv1,<br>                    self.w_conv1,<br>                    self.thre_conv1,<br>                    conv_step=self.step_conv1,<br>                )<br>                data_pooled1 = self.pooling(data_conved1, self.size_pooling1)<br>                shape_featuremap1 = np.shape(data_conved1)<br>                <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">                print(&#x27;  -----original shape   &#x27;, np.shape(data_train))</span><br><span class="hljs-string">                print(&#x27;  ---- after convolution  &#x27;,np.shape(data_conv1))</span><br><span class="hljs-string">                print(&#x27;  -----after pooling  &#x27;,np.shape(data_pooled1))</span><br><span class="hljs-string">               &quot;&quot;&quot;</span><br>                data_bp_input = self._expand(data_pooled1)<br>                bp_out1 = data_bp_input<br><br>                bp_net_j = np.dot(bp_out1, self.vji.T) - self.thre_bp2<br>                bp_out2 = self.sig(bp_net_j)<br>                bp_net_k = np.dot(bp_out2, self.wkj.T) - self.thre_bp3<br>                bp_out3 = self.sig(bp_net_k)<br><br>                <span class="hljs-comment"># --------------Model Leaning ------------------------</span><br>                <span class="hljs-comment"># calculate error and gradient---------------</span><br>                pd_k_all = np.multiply(<br>                    (data_teach - bp_out3), np.multiply(bp_out3, (<span class="hljs-number">1</span> - bp_out3))<br>                )<br>                pd_j_all = np.multiply(<br>                    np.dot(pd_k_all, self.wkj), np.multiply(bp_out2, (<span class="hljs-number">1</span> - bp_out2))<br>                )<br>                pd_i_all = np.dot(pd_j_all, self.vji)<br><br>                pd_conv1_pooled = pd_i_all / (self.size_pooling1 * self.size_pooling1)<br>                pd_conv1_pooled = pd_conv1_pooled.T.getA().tolist()<br>                pd_conv1_all = self._calculate_gradient_from_pool(<br>                    data_conved1,<br>                    pd_conv1_pooled,<br>                    shape_featuremap1[<span class="hljs-number">0</span>],<br>                    shape_featuremap1[<span class="hljs-number">1</span>],<br>                    self.size_pooling1,<br>                )<br>                <span class="hljs-comment"># weight and threshold learning process---------</span><br>                <span class="hljs-comment"># convolution layer</span><br>                <span class="hljs-keyword">for</span> k_conv <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.conv1[<span class="hljs-number">1</span>]):<br>                    pd_conv_list = self._expand_mat(pd_conv1_all[k_conv])<br>                    delta_w = self.rate_weight * np.dot(pd_conv_list, data_focus1)<br><br>                    self.w_conv1[k_conv] = self.w_conv1[k_conv] + delta_w.reshape(<br>                        (self.conv1[<span class="hljs-number">0</span>], self.conv1[<span class="hljs-number">0</span>])<br>                    )<br><br>                    self.thre_conv1[k_conv] = (<br>                        self.thre_conv1[k_conv]<br>                        - np.<span class="hljs-built_in">sum</span>(pd_conv1_all[k_conv]) * self.rate_thre<br>                    )<br>                <span class="hljs-comment"># all connected layer</span><br>                self.wkj = self.wkj + pd_k_all.T * bp_out2 * self.rate_weight<br>                self.vji = self.vji + pd_j_all.T * bp_out1 * self.rate_weight<br>                self.thre_bp3 = self.thre_bp3 - pd_k_all * self.rate_thre<br>                self.thre_bp2 = self.thre_bp2 - pd_j_all * self.rate_thre<br>                <span class="hljs-comment"># calculate the sum error of all single image</span><br>                errors = np.<span class="hljs-built_in">sum</span>(<span class="hljs-built_in">abs</span>(data_teach - bp_out3))<br>                error_count += errors<br>                <span class="hljs-comment"># print(&#x27;   ----Teach      &#x27;,data_teach)</span><br>                <span class="hljs-comment"># print(&#x27;   ----BP_output  &#x27;,bp_out3)</span><br>            rp = rp + <span class="hljs-number">1</span><br>            mse = error_count / patterns<br>            all_mse.append(mse)<br><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">draw_error</span>():<br>            yplot = [error_accuracy <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(n_repeat * <span class="hljs-number">1.2</span>))]<br>            plt.plot(all_mse, <span class="hljs-string">&quot;+-&quot;</span>)<br>            plt.plot(yplot, <span class="hljs-string">&quot;r--&quot;</span>)<br>            plt.xlabel(<span class="hljs-string">&quot;Learning Times&quot;</span>)<br>            plt.ylabel(<span class="hljs-string">&quot;All_mse&quot;</span>)<br>            plt.grid(<span class="hljs-literal">True</span>, alpha=<span class="hljs-number">0.5</span>)<br>            plt.show()<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;------------------Training Complished---------------------&quot;</span>)<br>        <span class="hljs-built_in">print</span>((<span class="hljs-string">&quot; - - Training epoch: &quot;</span>, rp, <span class="hljs-string">f&quot;     - - Mse: <span class="hljs-subst">&#123;mse:<span class="hljs-number">.6</span>f&#125;</span>&quot;</span>))<br>        <span class="hljs-keyword">if</span> draw_e:<br>            draw_error()<br>        <span class="hljs-keyword">return</span> mse<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, datas_test</span>):<br>        <span class="hljs-comment"># model predict</span><br>        produce_out = []<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-------------------Start Testing-------------------------&quot;</span>)<br>        <span class="hljs-built_in">print</span>((<span class="hljs-string">&quot; - - Shape: Test_Data  &quot;</span>, np.shape(datas_test)))<br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(datas_test)):<br>            data_test = np.asmatrix(datas_test[p])<br>            data_focus1, data_conved1 = self.convolute(<br>                data_test,<br>                self.conv1,<br>                self.w_conv1,<br>                self.thre_conv1,<br>                conv_step=self.step_conv1,<br>            )<br>            data_pooled1 = self.pooling(data_conved1, self.size_pooling1)<br>            data_bp_input = self._expand(data_pooled1)<br><br>            bp_out1 = data_bp_input<br>            bp_net_j = bp_out1 * self.vji.T - self.thre_bp2<br>            bp_out2 = self.sig(bp_net_j)<br>            bp_net_k = bp_out2 * self.wkj.T - self.thre_bp3<br>            bp_out3 = self.sig(bp_net_k)<br>            produce_out.extend(bp_out3.getA().tolist())<br>        res = [<span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(self.do_round, each)) <span class="hljs-keyword">for</span> each <span class="hljs-keyword">in</span> produce_out]<br>        <span class="hljs-keyword">return</span> np.asarray(res)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">convolution</span>(<span class="hljs-params">self, data</span>):<br>        <span class="hljs-comment"># return the data of image after convoluting process so we can check it out</span><br>        data_test = np.asmatrix(data)<br>        data_focus1, data_conved1 = self.convolute(<br>            data_test,<br>            self.conv1,<br>            self.w_conv1,<br>            self.thre_conv1,<br>            conv_step=self.step_conv1,<br>        )<br>        data_pooled1 = self.pooling(data_conved1, self.size_pooling1)<br><br>        <span class="hljs-keyword">return</span> data_conved1, data_pooled1<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    I will put the example on other file</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><p>torch官方代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> f<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        <span class="hljs-comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span><br>        <span class="hljs-comment"># kernel</span><br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-comment"># an affine operation: y = Wx + b</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>)  <span class="hljs-comment"># 5*5 from image dimension</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># Max pooling over a (2, 2) window</span><br>        x = f.max_pool2d(f.relu(self.conv1(x)), (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>        <span class="hljs-comment"># If the size is a square, you can specify with a single number</span><br>        x = f.max_pool2d(f.relu(self.conv2(x)), <span class="hljs-number">2</span>)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)  <span class="hljs-comment"># flatten all dimensions except the batch dimension</span><br>        x = f.relu(self.fc1(x))<br>        x = f.relu(self.fc2(x))<br>        x = self.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br>net = Net()<br><span class="hljs-built_in">print</span>(net)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL基础知识</title>
    <link href="/2024/06/18/MySQL/"/>
    <url>/2024/06/18/MySQL/</url>
    
    <content type="html"><![CDATA[<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><p><strong>sql</strong>:结构化查询语言，用于操作数据，通用绝大多数的数据库软件</p><h2 id="数据库的启动"><a href="#数据库的启动" class="headerlink" title="数据库的启动"></a>数据库的启动</h2><p>建议用管理员身份运行sql</p><p>启动：net start mysql80</p><p>停止：net stop mysql80</p><p>目前版本是mysql83</p><p>​<img src="/img/image-20240313094936-5gjkebp.png" alt="image">​</p><p>客户端连接：</p><p>1.mysql提供的客户端命名行工具</p><p>2.系统自带的的命名行工具执行指令（需要配置环境变量）</p><p>mysql [-h IP地址] [-p 端口] -u root -p</p><p>数据库模型</p><p>关系型数据库(RDBMS)</p><p>概念：建立在关系模型基础上，有多张相互连接的二维表组成的数据库</p><p>特点：使用表存储数据，格式统一，便于维护；使用SQL语言，标准统一，使用方便</p><p>数据模型</p><h3 id="语法特征"><a href="#语法特征" class="headerlink" title="语法特征"></a>语法特征</h3><p>1.大小写不敏感，关键字建议使用大写</p><p>2.可以单行和多行书写，最后以;号结束</p><p>3.SQL语句可以使用空格&#x2F;缩进来增强语句的可读性</p><p>4.支持注释</p><p>单行注释：– 注释内容（–后必须加空格）</p><p>单行注释：注释内容（#后面建议加空格）</p><p>多行注释：&#x2F;* 注释内容*&#x2F;</p><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p><strong>数据定义：DDL</strong></p><p>库的创建删除，表的创建删除</p><p><strong>数据操纵：DML</strong></p><p>新增数据，删除数据，修改数据</p><p><strong>数据控制：DCL</strong></p><p>新增用户，删除用户，密码修改，权限管理</p><p><strong>数据查询：DQL</strong></p><p>基于需求查询和计算数据</p><h3 id="简单语法"><a href="#简单语法" class="headerlink" title="简单语法"></a>简单语法</h3><p>show databases;  查看数据库</p><p>use 数据库名 使用某个数据库</p><p>show tables 查看数据库内有哪些表</p><p>exit 退出 MySQL 的命令环境</p><p>注：命令最后要加分号表示结束</p><h4 id="DDL-库管理"><a href="#DDL-库管理" class="headerlink" title="DDL-库管理"></a>DDL-库管理</h4><p>查看所有数据库 show databases;</p><p>查询当前数据库 select databases();</p><p>使用数据库 use 数据库名称;</p><p>创建数据库 creat database [if not exists]数据库名称 [default charset 字符集] [collate 排序规则];</p><p>删除数据库 drop database [if exists] 数据库名称;</p><h4 id="DDL-表管理"><a href="#DDL-表管理" class="headerlink" title="DDL-表管理"></a>DDL-表管理</h4><p>查看表 show tables;   (先选择数据库)</p><p>创建表 create table 表名称(列名称 列类型,  [comment 注释]……) [cmment 注释];</p><p><strong>列类型</strong>有 int 整数，float 浮点数，varchar(长度)  文本，长度位数字，做最大长度限制，data 日期类型，timestamp 时间戳类型</p><p>查询表结构 desc 表明;</p><p>删除表 drop table 表名称;  ， drop table if exists 表名称;</p><h4 id="DML-数据操作"><a href="#DML-数据操作" class="headerlink" title="DML -数据操作"></a>DML -数据操作</h4><p>DML 数据操作语言，用来对数据库中表的数据记录进行更新</p><h5 id="数据插入-insert"><a href="#数据插入-insert" class="headerlink" title="数据插入 insert"></a>数据插入 insert</h5><p>基础语法： insert into 表[(列 1,列 2,……,列 N)] values (值 1,值 2,……,值 N),[, (值 1,值 2,……,值 N),……(值 1,值 2,……,值 N)];</p><h5 id="数据删除-delect"><a href="#数据删除-delect" class="headerlink" title="数据删除 delect"></a>数据删除 delect</h5><p>基础语法：delect from 表名称 [where 条件判断];</p><h5 id="数据更新-update"><a href="#数据更新-update" class="headerlink" title="数据更新 update"></a>数据更新 update</h5><p>基础语法： update 表名 set 列&#x3D; 值 [where 条件判断];</p><p>注：字符串出现时要用引号包围</p><h4 id="DQL-数据查询"><a href="#DQL-数据查询" class="headerlink" title="DQL-数据查询"></a>DQL-数据查询</h4><p>通过 select 关键字开通的 sql 语句，来进行数据的查询</p><p>基础语法：select 字段列表 |* from 表 where 条件判断</p><p>select * from 表 输出全部</p><p>多个判断&amp;&amp;且 || 或</p><h5 id="分组聚合"><a href="#分组聚合" class="headerlink" title="分组聚合"></a>分组聚合</h5><p>基础语法：select 列，字段 | 聚合函数 from 表 [where 条件] group by 列</p><p>聚合函数有：</p><p>sum(列) 求和， avg(列) 求平均值，min(列) 求最小值，max(列) 求最大值，count(列 |*) 求数量</p><h5 id="排序分页"><a href="#排序分页" class="headerlink" title="排序分页"></a>排序分页</h5><p>对查询的结果，使用 order by 关键字，指定某个列进行语法排序</p><p>select 列 | 聚合函数 |* from 表</p><p>where……</p><p>group by……</p><p>order by……[asc(从小到大)|desc(从大到小)]</p><p>limit n[,m] 从第 n 条开始向后去 m 条</p><h3 id="通过-pycharm-运行-MYSQL"><a href="#通过-pycharm-运行-MYSQL" class="headerlink" title="通过 pycharm 运行 MYSQL"></a>通过 pycharm 运行 MYSQL</h3><h5 id="获取链接对象"><a href="#获取链接对象" class="headerlink" title="获取链接对象"></a>获取链接对象</h5><p>from pymysql import Connection 导入包</p><p>Connection(主机，端口，账户，密码)即可得到链接对象</p><p>链接对象.close()关闭和 MySQL 数据库的链接</p><h5 id="执行-SQL-查询"><a href="#执行-SQL-查询" class="headerlink" title="执行 SQL 查询"></a>执行 SQL 查询</h5><p>通过链接对象调用 cursor()方法，得到游标对象</p><p>游标对象.execute()执行 SQL 语句</p><p>游标对象.fetchall()得到的查询结果封装进入元组内</p><h5 id="数据插入"><a href="#数据插入" class="headerlink" title="数据插入"></a>数据插入</h5><p>对数据库的修改必须确认</p><p>commit 提交，通过链接对象.commit()即可确认此行为</p><p>设置自动提交</p><p>connection（autocommit&#x3D;Ture）</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p>]]></content>
    
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>农民的智能助手——锄禾</title>
    <link href="/2024/06/18/%E9%94%84%E7%A6%BEapp/"/>
    <url>/2024/06/18/%E9%94%84%E7%A6%BEapp/</url>
    
    <content type="html"><![CDATA[<p>项目名称：锄禾</p><p>提交日期：2024.06.11.</p><h1 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h1><h3 id="宏观背景"><a href="#宏观背景" class="headerlink" title="宏观背景"></a>宏观背景</h3><p>随着数字技术的飞速发展，农业正逐步迈入智能化时代。然而，广大农民群体在获取农业技术、市场信息及销售农产品方面仍面临诸多挑战。本项目旨在打造一款专注于服务农民的APP——“智慧农田”，结合先进的AI技术与便捷的移动互联网应用，以解决信息不对称、技术应用滞后及销售渠道受限等问题，促进农业生产的高效化、智能化，助力农民增收增效。</p><h3 id="产业背景"><a href="#产业背景" class="headerlink" title="产业背景"></a>产业背景</h3><p>核心功能;语音交互社区，农副产品交易平台，和AI大模型助手</p><p>服务对象：农名</p><h1 id="市场分析"><a href="#市场分析" class="headerlink" title="市场分析"></a>市场分析</h1><h2 id="目标市场"><a href="#目标市场" class="headerlink" title="目标市场"></a><strong>目标市场</strong></h2><p>通网率较高农村地区的农民</p><h3 id="目标用户界定"><a href="#目标用户界定" class="headerlink" title="目标用户界定"></a>目标用户界定</h3><p>我们的目标用户群定位为通网率较高的农村地区的农民，年龄主要分布在30至60岁之间，他们拥有一定的农业生产经验，渴望通过现代科技手段提升农作物产量、改善种植技术，并寻找更广阔的销售渠道以增加收入。这部分农民通常对智能手机有一定的操作基础，能够进行基本的互联网浏览和社交应用操作。</p><h2 id="竞争分析"><a href="#竞争分析" class="headerlink" title="竞争分析"></a><strong>竞争分析</strong></h2><p><strong>市场概览</strong>：</p><p>在目前的有关农业相关的app中，</p><h3 id="竞品分析"><a href="#竞品分析" class="headerlink" title="竞品分析"></a>竞品分析</h3><p><strong>竞品A</strong></p><p><strong>竞品B</strong></p><p><strong>竞品C</strong></p><h3 id="竞争优势"><a href="#竞争优势" class="headerlink" title="竞争优势"></a>竞争优势</h3><p>相对去其它的农业方面的app，我们具有以下优势</p><p><strong>个性化信息服务</strong>：通过AI技术实现精准推送，确保每位用户都能接收到与其种植作物、地理位置相关的最新资讯和技术指导。</p><p><strong>语音交互社区+</strong> ：打造</p><p><strong>智能AI大模型语音助手</strong>：集成先进的语音识别技术，方便不擅长文字输入的用户通过语音指令快速查询信息、发布产品，提升用户体验。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>综上所述，通过精准定位目标用户的具体需求，结合现有竞品的优劣分析，我们在提供个性化信息服务、优化学习体验、降低电商门槛、强化社区互动以及创新交互方式等方面，展现出独特的优势，从而在竞争激烈的市场中脱颖而出，更好地服务于农村地区的农民群体。</p><h2 id="市场趋势"><a href="#市场趋势" class="headerlink" title="市场趋势"></a><strong>市场趋势</strong></h2><p>探讨农业技术、移动应用、电子商务等领域的最新趋势，以及它们如何影响你的项目。</p><h1 id="产品与服务"><a href="#产品与服务" class="headerlink" title="产品与服务"></a>产品与服务</h1><h2 id="功能描述："><a href="#功能描述：" class="headerlink" title="功能描述："></a><strong>功能描述</strong>：</h2><p>‍</p><p><strong>1. 语音交互社区</strong></p><ul><li><strong>语音识别与发送</strong>：用户可通过语音指令发布问题、分享经验、搜索信息，系统自动识别并转换为文字，支持多种方言识别，降低操作难度。</li><li><strong>语音回复与通知</strong>：系统或社区成员的回复同样可以语音形式送达，用户可选择接收语音或文字通知。</li><li><strong>话题分类与推荐</strong>：自动将语音内容分类至相应话题区域，如病虫害防治、种植技巧、市场动态等，基于用户兴趣推荐相关内容。</li></ul><p><strong>2. 农副产品交易平台</strong></p><ul><li><strong>商品发布</strong>：农户可便捷上传自家农产品信息，包括图片、描述、价格等，支持语音录入产品详情。</li><li><strong>智能匹配</strong>：通过AI算法分析买家需求，向其推荐合适的产品，同时为卖家匹配潜在买家。</li><li><strong>安全支付</strong>：集成第三方支付平台，提供多种支付方式，确保交易安全，同时设定合理的交易手续费政策。</li><li><strong>评价与信用体系</strong>：买卖双方可互评，建立基于交易历史的信用评分系统，提高交易信誉。</li></ul><p><strong>3. AI大模型助手</strong></p><ul><li><strong>智能诊断</strong>：用户上传作物照片或描述症状，AI助手快速识别病虫害，提供防治建议。</li><li><strong>天气与土壤分析</strong>：根据地理位置，提供精准天气预报，结合土壤数据给出种植建议。</li><li><strong>市场行情预测</strong>：利用大数据分析，预测各类农产品的未来价格趋势，辅助农户做出种植决策。</li><li><strong>个性化农技推送</strong>：根据用户种植作物类型、地区气候等因素，推送定制化的农业技术和市场资讯。</li></ul><p><strong>4. 农业知识库</strong></p><ul><li><strong>视频教程</strong>：海量农业技术视频，涵盖种植、养殖、病虫害防治等，支持离线下载。</li><li><strong>专家问答</strong>：连线农业专家，用户可提交问题，获取权威解答，支持预约一对一咨询服务。</li><li><strong>案例分享</strong>：成功案例展示，包括新品种试种、高效种植模式等，激励学习与实践。</li></ul><p><strong>5. 用户个人中心</strong></p><ul><li><strong>账户管理</strong>：个人信息编辑、密码修改、绑定银行卡等。</li><li><strong>交易记录</strong>：查看历史交易详情，管理订单状态，申请售后。</li><li><strong>收藏与关注</strong>：收藏感兴趣的内容、关注专家或农户，便于后续访问。</li><li><strong>积分与奖励</strong>：参与社区互动、交易等可累积积分，兑换优惠券或实体奖品。</li></ul><h2 id="技术架构："><a href="#技术架构：" class="headerlink" title="技术架构："></a><strong>技术架构</strong>：</h2><h4 id="1-前端界面设计"><a href="#1-前端界面设计" class="headerlink" title="1. 前端界面设计"></a>1. 前端界面设计</h4><p><strong>技术栈</strong>：采用React Native进行跨平台开发，确保应用能在iOS和Android设备上流畅运行。</p><p><strong>UI&#x2F;UX设计</strong>：设计符合农民使用习惯的简洁界面，注重可读性和易用性。采用大字体、高对比度色彩和直观图标，确保在各种光照条件下都能轻松阅读。集成语音识别组件，便于用户通过语音命令操作。</p><p><strong>响应式布局</strong>：确保应用界面在不同尺寸屏幕上的自适应显示，优化移动端用户体验。</p><h4 id="2-后端支持架构"><a href="#2-后端支持架构" class="headerlink" title="2. 后端支持架构"></a>2. 后端支持架构</h4><p><strong>技术选型</strong>：使用Node.js搭配Express框架搭建后端服务，因其非阻塞I&#x2F;O和高并发处理能力适合实时数据交互场景。同时使用Django作为备选方案，以满足复杂业务逻辑需求。</p><p><strong>API设计</strong>：遵循RESTful原则设计API接口，确保数据交互的高效与标准化。对于实时交互需求，可采用WebSocket技术实现实时通信。</p><p><strong>云服务</strong>：依托AWS、阿里云或腾讯云等云服务商，利用其服务器、数据库、CDN等服务，保障应用的稳定运行和数据安全。</p><h4 id="3-数据库设计"><a href="#3-数据库设计" class="headerlink" title="3. 数据库设计"></a>3. 数据库设计</h4><p><strong>主数据库</strong>：采用MySQL作为关系型数据库存储用户账户、商品信息、交易记录等结构化数据。考虑使用NoSQL数据库（如MongoDB）来处理大量非结构化数据，如用户生成的内容、图片资料等。</p><p><strong>缓存策略</strong>：利用Redis作为缓存层，提高热点数据访问速度，减轻数据库压力。</p><p><strong>数据备份与恢复</strong>：定期自动备份数据库，确保数据安全，设置灾难恢复策略，以防数据丢失。</p><h4 id="4-安全措施"><a href="#4-安全措施" class="headerlink" title="4. 安全措施"></a>4. 安全措施</h4><p><strong>数据加密</strong>：对敏感信息（如用户密码、交易数据）采用HTTPS协议传输，并使用AES加密算法进行存储加密。</p><p><strong>身份验证与授权</strong>：实现OAuth2.0进行用户身份验证，确保每次请求的安全性。根据角色分配不同的访问权限，限制敏感操作。</p><p><strong>防止SQL注入和XSS攻击</strong>：采用参数化查询和HTML编码等方法，防止恶意攻击。</p><p><strong>DDoS防护</strong>：与云服务商合作，利用其提供的DDoS防护服务，抵御大规模网络攻击。</p><h4 id="5-AI技术集成"><a href="#5-AI技术集成" class="headerlink" title="5. AI技术集成"></a>5. AI技术集成</h4><p><strong>语音识别与自然语言处理</strong>：采用阿里云的语音识别服务，结合自然语言处理技术（BERT模型），实现语音交互功能。</p><p><strong>个性化推荐</strong>：基于用户行为、地理位置、作物类型等数据，利用深度学习模型提供个性化内容推荐。</p><p>‍</p><h2 id="用户体验："><a href="#用户体验：" class="headerlink" title="用户体验："></a><strong>用户体验</strong>：</h2><h3 id="1-用户研究与反馈循环"><a href="#1-用户研究与反馈循环" class="headerlink" title="1.用户研究与反馈循环"></a>1.用户研究与反馈循环</h3><p><strong>用户画像</strong>：在设计初期，通过调研明确目标用户群体的需求、习惯和偏好，创建详细用户画像。</p><p><strong>原型测试</strong>：设计低 fidelity原型后，邀请真实用户参与测试，收集反馈，及时调整设计。</p><p><strong>持续迭代</strong>：发布后继续收集用户反馈，通过数据分析识别使用痛点，定期更新APP，不断优化体验。</p><h3 id="2-界面设计原则"><a href="#2-界面设计原则" class="headerlink" title="2. 界面设计原则"></a>2. 界面设计原则</h3><p><strong>简洁直观</strong>：保持界面清晰，避免过多复杂元素。重要信息和操作应一目了然，减少用户的学习成本。</p><p><strong>色彩与图标</strong>：使用高对比度色彩，确保在户外强光下也能清晰阅读。图标设计应直观，能快速传达其功能意义。</p><p><strong>适配性</strong>：确保界面在不同设备、屏幕尺寸和方向上均能良好展示，提供良好的响应式设计。</p><h3 id="3-易用性功能"><a href="#3-易用性功能" class="headerlink" title="3. 易用性功能"></a>3. 易用性功能</h3><p><strong>语音导航</strong>：鉴于部分农村地区用户可能不擅长文字输入，集成高质量的语音识别和语音反馈功能，支持语音命令操作和信息获取。</p><p><strong>大按钮与字体</strong>：考虑到用户的实际操作环境和视力情况，设计大尺寸的触摸目标和易于阅读的大号字体。</p><p><strong>离线模式</strong>：考虑农村网络不稳定的情况，设计离线功能，允许用户在无网络时查看已下载的内容或记录数据，待网络恢复时同步。</p><h3 id="4-互动性增强"><a href="#4-互动性增强" class="headerlink" title="4. 互动性增强"></a>4. 互动性增强</h3><p><strong>即时反馈</strong>：对用户的每一个操作给予即时视觉或听觉反馈，比如按钮点击效果、加载提示等，让用户知道系统正在响应。</p><p><strong>社区互动</strong>：建立用户交流论坛或评论区，鼓励用户分享经验、提问和解答，增强用户之间的互动性。</p><p><strong>个性化推送</strong>：根据用户行为和偏好，推送个性化内容和提醒，如天气预报、市场动态、农技知识等，增加用户粘性。</p><h3 id="5-教育与引导"><a href="#5-教育与引导" class="headerlink" title="5. 教育与引导"></a>5. 教育与引导</h3><p><strong>新手引导</strong>：为新用户提供简短而有效的引导教程，展示APP的主要功能和使用方法。</p><p><strong>帮助中心</strong>：内置详尽的帮助文档和FAQ，方便用户随时查找问题解决方案。</p><h1 id="运营与营销策略"><a href="#运营与营销策略" class="headerlink" title="运营与营销策略"></a>运营与营销策略</h1><h2 id="推广计划："><a href="#推广计划：" class="headerlink" title="推广计划："></a><strong>推广计划</strong>：</h2><p>主要是线上，以广告形式投放链接</p><h2 id="合作伙伴："><a href="#合作伙伴：" class="headerlink" title="合作伙伴："></a><strong>合作伙伴</strong>：</h2><p>政府农业部门、农业科技公司、农村合作社</p><h2 id="盈利模式："><a href="#盈利模式：" class="headerlink" title="盈利模式："></a><strong>盈利模式</strong>：</h2><p>前期在过度界面投放广告，流量大了可以引入电商</p><h1 id="项目实施计划"><a href="#项目实施计划" class="headerlink" title="项目实施计划"></a>项目实施计划</h1><h2 id="时间表："><a href="#时间表：" class="headerlink" title="时间表："></a><strong>时间表</strong>：</h2><h3 id="第一阶段：开发阶段（第1-11周）"><a href="#第一阶段：开发阶段（第1-11周）" class="headerlink" title="第一阶段：开发阶段（第1-11周）"></a>第一阶段：开发阶段（第1-11周）</h3><ul><li><strong>第1-3周</strong>：前端开发启动，完成基础界面设计和主要功能模块开发。</li><li><strong>第4-5周</strong>：后端服务开发，包括API设计、数据库架构搭建、服务器配置。</li><li><strong>第6-7周</strong>：集成语音识别和AI模型功能，进行前后端联调。</li><li><strong>第8-9周</strong>：完成交易系统开发与支付接口集成，测试基础功能模块。</li><li><strong>第10-11周</strong>：完成社区功能开发，优化用户体验，进行内部测试，修复初期发现的bug。</li></ul><h3 id="第二阶段：测试与优化（第12-14周）"><a href="#第二阶段：测试与优化（第12-14周）" class="headerlink" title="第二阶段：测试与优化（第12-14周）"></a>第二阶段：测试与优化（第12-14周）</h3><ul><li><strong>第12周</strong>：全面功能测试，包括性能测试、兼容性测试、安全测试。</li><li><strong>第13周</strong>：用户体验测试，邀请目标用户参与Beta测试，收集反馈。</li><li><strong>第14周</strong>：根据测试反馈进行最后的修正，准备上线版本，完成所有文档编写。</li></ul><h3 id="第三阶段：上线与推广（第15-18周）"><a href="#第三阶段：上线与推广（第15-18周）" class="headerlink" title="第三阶段：上线与推广（第15-18周）"></a>第三阶段：上线与推广（第15-18周）</h3><ul><li><p><strong>第15周</strong>：正式上线前的准备工作，包括服务器部署、数据迁移、最后的检查。</p></li><li><p><strong>第16周</strong>：正式上线，监控系统稳定性，处理紧急问题。</p></li><li><p><strong>第17-18周</strong>：开始推广活动，包括社交媒体宣传、合作伙伴推广、线下活动、SEO优化、ASO优化等。</p><ul><li>第17周：启动初期推广活动，如软文发布、KOL合作。</li><li>第18周：根据推广效果调整策略，持续优化推广渠道，扩大用户基数。</li></ul></li></ul><h3 id="第五阶段：后期运营与迭代（第19周起）"><a href="#第五阶段：后期运营与迭代（第19周起）" class="headerlink" title="第五阶段：后期运营与迭代（第19周起）"></a>第五阶段：后期运营与迭代（第19周起）</h3><ul><li><strong>第19周及以后</strong>：持续收集用户反馈，进行数据分析，根据市场反馈进行功能迭代和优化。</li><li>定期评估推广效果，调整市场策略，增加用户留存和活跃度。</li><li>每季度或半年进行一次大的版本更新，引入新功能或优化现有功能。</li></ul><h2 id="团队介绍："><a href="#团队介绍：" class="headerlink" title="团队介绍："></a><strong>团队介绍</strong>：</h2><p>介绍核心团队成员及其职责、专业背景。</p><h2 id="预算安排："><a href="#预算安排：" class="headerlink" title="预算安排："></a><strong>预算安排</strong>：</h2><p>列出项目各阶段的预算分配，包括研发成本、运营成本、市场营销费用等。</p><h1 id="风险评估与应对措施"><a href="#风险评估与应对措施" class="headerlink" title="风险评估与应对措施"></a>风险评估与应对措施</h1><h2 id="风险识别："><a href="#风险识别：" class="headerlink" title="风险识别："></a><strong>风险识别</strong>：</h2><p>分析可能遇到的技术风险、市场风险、财务风险等。</p><h2 id="应对策略："><a href="#应对策略：" class="headerlink" title="应对策略："></a><strong>应对策略</strong>：</h2><p>针对每个风险提出具体的预防和应对措施。</p><p>‍</p><p>‍</p><p>‍</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
